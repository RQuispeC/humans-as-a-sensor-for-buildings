{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from modeling_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available participants: \n",
      "['cresh07' 'cresh10' 'cresh08' 'cresh12' 'cresh09' 'cresh06' 'cresh02'\n",
      " 'cresh13' 'cresh15' 'cresh03' 'cresh14' 'cresh11' 'cresh05' 'cresh01'\n",
      " 'cresh04' 'cresh22' 'cresh16' 'cresh19' 'cresh21' 'cresh26' 'cresh29'\n",
      " 'cresh27' 'cresh23' 'cresh20' 'cresh18' 'cresh30' 'cresh17' 'cresh24'\n",
      " 'cresh28' 'cresh25']\n"
     ]
    }
   ],
   "source": [
    "seed = 13\n",
    "dataframes_names = ['fs1', 'fs2', 'fs3', 'fs4', 'fs5', 'fs6']\n",
    "folder_path = 'data-processed-preferences/'\n",
    "file_date = '2019-11-15'\n",
    "\n",
    "# load any of the dataset just to get the complete list of participants\n",
    "dataframe_names = pd.read_csv('../' + folder_path + file_date + '_'  + dataframes_names[0] + \".csv\")\n",
    "participant_list = dataframe_names['user_id'].unique()\n",
    "print(\"Available participants: \\n{}\".format(participant_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# FS1: Time + Sensing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from: data-processed-preferences/2019-11-15_fs1\n"
     ]
    }
   ],
   "source": [
    "df_file = folder_path + file_date + \"_\" +  dataframes_names[0]\n",
    "print(\"Loading files from: {}\".format(df_file))\n",
    "\n",
    "list_micro_fs1_thermal = {}\n",
    "list_macro_fs1_thermal = {}\n",
    "\n",
    "list_micro_fs1_light = {}\n",
    "list_macro_fs1_light = {}\n",
    "\n",
    "list_micro_fs1_aural = {}\n",
    "list_macro_fs1_aural = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: cresh07\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.47368421052631576\n",
      "F1 micro on validation set: 0.47368421052631576\n",
      "F1 macro on validation set: 0.21428571428571427\n",
      "Confusion Matrix: \n",
      "[[0 2 0]\n",
      " [0 9 8]\n",
      " [0 0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.82      0.53      0.64        17\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.47        19\n",
      "   macro avg       0.27      0.18      0.21        19\n",
      "weighted avg       0.73      0.47      0.58        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9473684210526315\n",
      "F1 micro on validation set: 0.9473684210526315\n",
      "F1 macro on validation set: 0.4864864864864865\n",
      "Confusion Matrix: \n",
      "[[18  1]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.95      0.97        19\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.50      0.47      0.49        19\n",
      "weighted avg       1.00      0.95      0.97        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9473684210526315\n",
      "F1 micro on validation set: 0.9473684210526315\n",
      "F1 macro on validation set: 0.4864864864864865\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        18\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.47      0.50      0.49        19\n",
      "weighted avg       0.90      0.95      0.92        19\n",
      "\n",
      "Participant: cresh10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6111111111111112\n",
      "F1 micro on validation set: 0.6111111111111112\n",
      "F1 macro on validation set: 0.3733333333333333\n",
      "Confusion Matrix: \n",
      "[[0 1 0]\n",
      " [0 9 4]\n",
      " [0 2 2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.75      0.69      0.72        13\n",
      "        11.0       0.33      0.50      0.40         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.36      0.40      0.37        18\n",
      "weighted avg       0.62      0.61      0.61        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.30303030303030304\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.83      1.00      0.91        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.28      0.33      0.30        18\n",
      "weighted avg       0.69      0.83      0.76        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.7222222222222222\n",
      "F1 micro on validation set: 0.7222222222222222\n",
      "F1 macro on validation set: 0.41935483870967744\n",
      "Confusion Matrix: \n",
      "[[13  4]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.93      0.76      0.84        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.46      0.38      0.42        18\n",
      "weighted avg       0.88      0.72      0.79        18\n",
      "\n",
      "Participant: cresh08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6875\n",
      "F1 micro on validation set: 0.6875\n",
      "F1 macro on validation set: 0.4074074074074074\n",
      "Confusion Matrix: \n",
      "[[11  5]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.69      0.81        16\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.50      0.34      0.41        16\n",
      "weighted avg       1.00      0.69      0.81        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8125\n",
      "F1 micro on validation set: 0.8125\n",
      "F1 macro on validation set: 0.4482758620689655\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.81      1.00      0.90        13\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.41      0.50      0.45        16\n",
      "weighted avg       0.66      0.81      0.73        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9375\n",
      "F1 micro on validation set: 0.9375\n",
      "F1 macro on validation set: 0.4838709677419355\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        15\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.47      0.50      0.48        16\n",
      "weighted avg       0.88      0.94      0.91        16\n",
      "\n",
      "Participant: cresh12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.45\n",
      "F1 micro on validation set: 0.45\n",
      "F1 macro on validation set: 0.3255360623781676\n",
      "Confusion Matrix: \n",
      "[[0 3 0]\n",
      " [0 4 1]\n",
      " [0 7 5]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.29      0.80      0.42         5\n",
      "        11.0       0.83      0.42      0.56        12\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.37      0.41      0.33        20\n",
      "weighted avg       0.57      0.45      0.44        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9\n",
      "F1 micro on validation set: 0.9\n",
      "F1 macro on validation set: 0.4736842105263158\n",
      "Confusion Matrix: \n",
      "[[ 0  2]\n",
      " [ 0 18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      1.00      0.95        18\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.45      0.50      0.47        20\n",
      "weighted avg       0.81      0.90      0.85        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.9\n",
      "F1 micro on validation set: 0.9\n",
      "F1 macro on validation set: 0.803921568627451\n",
      "Confusion Matrix: \n",
      "[[16  0]\n",
      " [ 2  2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.89      1.00      0.94        16\n",
      "        11.0       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.94      0.75      0.80        20\n",
      "weighted avg       0.91      0.90      0.89        20\n",
      "\n",
      "Participant: cresh09\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.2\n",
      "F1 micro on validation set: 0.20000000000000004\n",
      "F1 macro on validation set: 0.13012477718360071\n",
      "Confusion Matrix: \n",
      "[[ 0  0  1]\n",
      " [ 0  1 15]\n",
      " [ 0  0  3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       1.00      0.06      0.12        16\n",
      "        11.0       0.16      1.00      0.27         3\n",
      "\n",
      "    accuracy                           0.20        20\n",
      "   macro avg       0.39      0.35      0.13        20\n",
      "weighted avg       0.82      0.20      0.14        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.95\n",
      "F1 micro on validation set: 0.9500000000000001\n",
      "F1 macro on validation set: 0.48717948717948717\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        19\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.47      0.50      0.49        20\n",
      "weighted avg       0.90      0.95      0.93        20\n",
      "\n",
      "Participant: cresh06\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.3877551020408163\n",
      "F1 micro on validation set: 0.3877551020408163\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[ 7  1 12]\n",
      " [ 9 12  2]\n",
      " [ 6  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.32      0.35      0.33        20\n",
      "        10.0       0.92      0.52      0.67        23\n",
      "        11.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.39        49\n",
      "   macro avg       0.41      0.29      0.33        49\n",
      "weighted avg       0.56      0.39      0.45        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8367346938775511\n",
      "F1 micro on validation set: 0.8367346938775511\n",
      "F1 macro on validation set: 0.45555555555555555\n",
      "Confusion Matrix: \n",
      "[[ 0  8]\n",
      " [ 0 41]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         8\n",
      "        10.0       0.84      1.00      0.91        41\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.42      0.50      0.46        49\n",
      "weighted avg       0.70      0.84      0.76        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8571428571428571\n",
      "F1 micro on validation set: 0.8571428571428571\n",
      "F1 macro on validation set: 0.4615384615384615\n",
      "Confusion Matrix: \n",
      "[[42  0]\n",
      " [ 7  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.86      1.00      0.92        42\n",
      "        11.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.86        49\n",
      "   macro avg       0.43      0.50      0.46        49\n",
      "weighted avg       0.73      0.86      0.79        49\n",
      "\n",
      "Participant: cresh02\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.28070175438596495\n",
      "Confusion Matrix: \n",
      "[[ 0  2  1]\n",
      " [ 0  0  3]\n",
      " [ 1  1 16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.00      0.00      0.00         3\n",
      "        11.0       0.80      0.89      0.84        18\n",
      "\n",
      "    accuracy                           0.67        24\n",
      "   macro avg       0.27      0.30      0.28        24\n",
      "weighted avg       0.60      0.67      0.63        24\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.2916666666666667\n",
      "F1 micro on validation set: 0.2916666666666667\n",
      "F1 macro on validation set: 0.2777067348678602\n",
      "Confusion Matrix: \n",
      "[[1 0 1]\n",
      " [4 4 4]\n",
      " [1 7 2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.17      0.50      0.25         2\n",
      "        10.0       0.36      0.33      0.35        12\n",
      "        11.0       0.29      0.20      0.24        10\n",
      "\n",
      "    accuracy                           0.29        24\n",
      "   macro avg       0.27      0.34      0.28        24\n",
      "weighted avg       0.31      0.29      0.29        24\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.5416666666666666\n",
      "F1 micro on validation set: 0.5416666666666666\n",
      "F1 macro on validation set: 0.5208711433756805\n",
      "Confusion Matrix: \n",
      "[[9 9]\n",
      " [2 4]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.82      0.50      0.62        18\n",
      "        11.0       0.31      0.67      0.42         6\n",
      "\n",
      "    accuracy                           0.54        24\n",
      "   macro avg       0.56      0.58      0.52        24\n",
      "weighted avg       0.69      0.54      0.57        24\n",
      "\n",
      "Participant: cresh13\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.7150997150997151\n",
      "Confusion Matrix: \n",
      "[[ 4  1]\n",
      " [ 4 11]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.50      0.80      0.62         5\n",
      "        11.0       0.92      0.73      0.81        15\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.71      0.77      0.72        20\n",
      "weighted avg       0.81      0.75      0.76        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.45\n",
      "F1 micro on validation set: 0.45\n",
      "F1 macro on validation set: 0.4373401534526854\n",
      "Confusion Matrix: \n",
      "[[3 3]\n",
      " [8 6]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.27      0.50      0.35         6\n",
      "        10.0       0.67      0.43      0.52        14\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.47      0.46      0.44        20\n",
      "weighted avg       0.55      0.45      0.47        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.65\n",
      "F1 micro on validation set: 0.65\n",
      "F1 macro on validation set: 0.6491228070175439\n",
      "Confusion Matrix: \n",
      "[[6 6]\n",
      " [1 7]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.86      0.50      0.63        12\n",
      "        11.0       0.54      0.88      0.67         8\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.70      0.69      0.65        20\n",
      "weighted avg       0.73      0.65      0.65        20\n",
      "\n",
      "Participant: cresh15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9333333333333333\n",
      "F1 micro on validation set: 0.9333333333333333\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0 14]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.00      0.00      0.00         0\n",
      "        11.0       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.33      0.33      0.33        15\n",
      "weighted avg       0.93      0.93      0.93        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.06666666666666667\n",
      "F1 micro on validation set: 0.06666666666666667\n",
      "F1 macro on validation set: 0.0625\n",
      "Confusion Matrix: \n",
      "[[ 0 14]\n",
      " [ 0  1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00        14\n",
      "        10.0       0.07      1.00      0.12         1\n",
      "\n",
      "    accuracy                           0.07        15\n",
      "   macro avg       0.03      0.50      0.06        15\n",
      "weighted avg       0.00      0.07      0.01        15\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.9333333333333333\n",
      "F1 micro on validation set: 0.9333333333333333\n",
      "F1 macro on validation set: 0.8148148148148149\n",
      "Confusion Matrix: \n",
      "[[ 1  0]\n",
      " [ 1 13]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.50      1.00      0.67         1\n",
      "        11.0       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.75      0.96      0.81        15\n",
      "weighted avg       0.97      0.93      0.94        15\n",
      "\n",
      "Participant: cresh03\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.45454545454545453\n",
      "Confusion Matrix: \n",
      "[[15  3]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.83      0.91        18\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.50      0.42      0.45        18\n",
      "weighted avg       1.00      0.83      0.91        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.3888888888888889\n",
      "F1 micro on validation set: 0.3888888888888889\n",
      "F1 macro on validation set: 0.42825311942959\n",
      "Confusion Matrix: \n",
      "[[3 0 0]\n",
      " [2 3 1]\n",
      " [0 8 1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.60      1.00      0.75         3\n",
      "        10.0       0.27      0.50      0.35         6\n",
      "        11.0       0.50      0.11      0.18         9\n",
      "\n",
      "    accuracy                           0.39        18\n",
      "   macro avg       0.46      0.54      0.43        18\n",
      "weighted avg       0.44      0.39      0.33        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9444444444444444\n",
      "F1 micro on validation set: 0.9444444444444444\n",
      "F1 macro on validation set: 0.4857142857142857\n",
      "Confusion Matrix: \n",
      "[[17  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.47      0.50      0.49        18\n",
      "weighted avg       0.89      0.94      0.92        18\n",
      "\n",
      "Participant: cresh14\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.4074074074074074\n",
      "F1 micro on validation set: 0.4074074074074074\n",
      "F1 macro on validation set: 0.33333333333333337\n",
      "Confusion Matrix: \n",
      "[[ 1  6]\n",
      " [10 10]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.09      0.14      0.11         7\n",
      "        10.0       0.62      0.50      0.56        20\n",
      "\n",
      "    accuracy                           0.41        27\n",
      "   macro avg       0.36      0.32      0.33        27\n",
      "weighted avg       0.49      0.41      0.44        27\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[27]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           1.00        27\n",
      "   macro avg       1.00      1.00      1.00        27\n",
      "weighted avg       1.00      1.00      1.00        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9629629629629629\n",
      "F1 micro on validation set: 0.9629629629629629\n",
      "F1 macro on validation set: 0.49056603773584906\n",
      "Confusion Matrix: \n",
      "[[26  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      1.00      0.98        26\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        27\n",
      "   macro avg       0.48      0.50      0.49        27\n",
      "weighted avg       0.93      0.96      0.94        27\n",
      "\n",
      "Participant: cresh11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[8 0]\n",
      " [8 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.50      1.00      0.67         8\n",
      "        11.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.25\n",
      "F1 micro on validation set: 0.25\n",
      "F1 macro on validation set: 0.25\n",
      "Confusion Matrix: \n",
      "[[ 2  2]\n",
      " [10  2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.17      0.50      0.25         4\n",
      "        11.0       0.50      0.17      0.25        12\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.33      0.33      0.25        16\n",
      "weighted avg       0.42      0.25      0.25        16\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.27777777777777773\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 15  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.71      1.00      0.83        15\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.24      0.33      0.28        21\n",
      "weighted avg       0.51      0.71      0.60        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8571428571428571\n",
      "F1 micro on validation set: 0.8571428571428571\n",
      "F1 macro on validation set: 0.3076923076923077\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 18  1]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      0.95      0.92        19\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86        21\n",
      "   macro avg       0.30      0.32      0.31        21\n",
      "weighted avg       0.81      0.86      0.84        21\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "Participant: cresh01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6190476190476191\n",
      "F1 micro on validation set: 0.6190476190476191\n",
      "F1 macro on validation set: 0.25490196078431376\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 13  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.62      1.00      0.76        13\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.62        21\n",
      "   macro avg       0.21      0.33      0.25        21\n",
      "weighted avg       0.38      0.62      0.47        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.42857142857142855\n",
      "F1 micro on validation set: 0.42857142857142855\n",
      "F1 macro on validation set: 0.24603174603174605\n",
      "Confusion Matrix: \n",
      "[[ 1 10  0]\n",
      " [ 0  8  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       1.00      0.09      0.17        11\n",
      "        10.0       0.40      1.00      0.57         8\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.43        21\n",
      "   macro avg       0.47      0.36      0.25        21\n",
      "weighted avg       0.68      0.43      0.30        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9047619047619048\n",
      "F1 micro on validation set: 0.9047619047619048\n",
      "F1 macro on validation set: 0.47500000000000003\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.90      1.00      0.95        19\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.45      0.50      0.48        21\n",
      "weighted avg       0.82      0.90      0.86        21\n",
      "\n",
      "Participant: cresh04\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.25\n",
      "F1 micro on validation set: 0.25\n",
      "F1 macro on validation set: 0.19413919413919412\n",
      "Confusion Matrix: \n",
      "[[3 2 0]\n",
      " [5 1 0]\n",
      " [1 4 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.33      0.60      0.43         5\n",
      "        10.0       0.14      0.17      0.15         6\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.16      0.26      0.19        16\n",
      "weighted avg       0.16      0.25      0.19        16\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.9375\n",
      "F1 micro on validation set: 0.9375\n",
      "F1 macro on validation set: 0.8160919540229885\n",
      "Confusion Matrix: \n",
      "[[14  0]\n",
      " [ 1  1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.93      1.00      0.97        14\n",
      "        11.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.97      0.75      0.82        16\n",
      "weighted avg       0.94      0.94      0.93        16\n",
      "\n",
      "Participant: cresh16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.2777777777777778\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 20  1]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.74      0.95      0.83        21\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.25      0.32      0.28        28\n",
      "weighted avg       0.56      0.71      0.62        28\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Participant: cresh19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.625\n",
      "F1 micro on validation set: 0.625\n",
      "F1 macro on validation set: 0.25641025641025644\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.62      1.00      0.77        10\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.21      0.33      0.26        16\n",
      "weighted avg       0.39      0.62      0.48        16\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh21\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.5714285714285714\n",
      "F1 micro on validation set: 0.5714285714285714\n",
      "F1 macro on validation set: 0.5552941176470587\n",
      "Confusion Matrix: \n",
      "[[8 0]\n",
      " [9 4]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.47      1.00      0.64         8\n",
      "        11.0       1.00      0.31      0.47        13\n",
      "\n",
      "    accuracy                           0.57        21\n",
      "   macro avg       0.74      0.65      0.56        21\n",
      "weighted avg       0.80      0.57      0.54        21\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9523809523809523\n",
      "F1 micro on validation set: 0.9523809523809523\n",
      "F1 macro on validation set: 0.4878048780487805\n",
      "Confusion Matrix: \n",
      "[[20  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.98        20\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.48      0.50      0.49        21\n",
      "weighted avg       0.91      0.95      0.93        21\n",
      "\n",
      "Participant: cresh26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8235294117647058\n",
      "F1 micro on validation set: 0.8235294117647058\n",
      "F1 macro on validation set: 0.3010752688172043\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0 14  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.82      1.00      0.90        14\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.27      0.33      0.30        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8235294117647058\n",
      "F1 micro on validation set: 0.8235294117647058\n",
      "F1 macro on validation set: 0.45161290322580644\n",
      "Confusion Matrix: \n",
      "[[14  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.82      1.00      0.90        14\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.41      0.50      0.45        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8823529411764706\n",
      "F1 micro on validation set: 0.8823529411764706\n",
      "F1 macro on validation set: 0.46875\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      1.00      0.94        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.44      0.50      0.47        17\n",
      "weighted avg       0.78      0.88      0.83        17\n",
      "\n",
      "Participant: cresh29\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Participant: cresh27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9166666666666666\n",
      "F1 micro on validation set: 0.9166666666666666\n",
      "F1 macro on validation set: 0.4782608695652174\n",
      "Confusion Matrix: \n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.92      1.00      0.96        11\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.7\n",
      "Confusion Matrix: \n",
      "[[9 1]\n",
      " [1 1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.90      0.90      0.90        10\n",
      "        11.0       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.70      0.70      0.70        12\n",
      "weighted avg       0.83      0.83      0.83        12\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[12]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Participant: cresh23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.2666666666666667\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 12  3]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.80      0.80      0.80        15\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.27      0.27      0.27        18\n",
      "weighted avg       0.67      0.67      0.67        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7222222222222222\n",
      "F1 micro on validation set: 0.7222222222222222\n",
      "F1 macro on validation set: 0.27956989247311825\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 13  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.72      1.00      0.84        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.24      0.33      0.28        18\n",
      "weighted avg       0.52      0.72      0.61        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.4444444444444444\n",
      "F1 micro on validation set: 0.4444444444444444\n",
      "F1 macro on validation set: 0.30769230769230765\n",
      "Confusion Matrix: \n",
      "[[8 1]\n",
      " [9 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.47      0.89      0.62         9\n",
      "        11.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.44        18\n",
      "   macro avg       0.24      0.44      0.31        18\n",
      "weighted avg       0.24      0.44      0.31        18\n",
      "\n",
      "Participant: cresh20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.7222222222222222\n",
      "F1 micro on validation set: 0.7222222222222222\n",
      "F1 macro on validation set: 0.41935483870967744\n",
      "Confusion Matrix: \n",
      "[[ 0  1]\n",
      " [ 4 13]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.46      0.38      0.42        18\n",
      "weighted avg       0.88      0.72      0.79        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7777777777777778\n",
      "F1 micro on validation set: 0.7777777777777778\n",
      "F1 macro on validation set: 0.43750000000000006\n",
      "Confusion Matrix: \n",
      "[[14  4]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.78      0.88        18\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.50      0.39      0.44        18\n",
      "weighted avg       1.00      0.78      0.88        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.72\n",
      "F1 micro on validation set: 0.72\n",
      "F1 macro on validation set: 0.27906976744186046\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 18  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.72      1.00      0.84        18\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.72        25\n",
      "   macro avg       0.24      0.33      0.28        25\n",
      "weighted avg       0.52      0.72      0.60        25\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[25]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.92\n",
      "F1 micro on validation set: 0.92\n",
      "F1 macro on validation set: 0.4791666666666667\n",
      "Confusion Matrix: \n",
      "[[23  1]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      0.96      0.96        24\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        25\n",
      "   macro avg       0.48      0.48      0.48        25\n",
      "weighted avg       0.92      0.92      0.92        25\n",
      "\n",
      "Participant: cresh30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5384615384615384\n",
      "F1 micro on validation set: 0.5384615384615384\n",
      "F1 macro on validation set: 0.2333333333333333\n",
      "Confusion Matrix: \n",
      "[[0 2 0]\n",
      " [0 7 3]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.70      0.70      0.70        10\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.23      0.23      0.23        13\n",
      "weighted avg       0.54      0.54      0.54        13\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.7692307692307693\n",
      "F1 micro on validation set: 0.7692307692307693\n",
      "F1 macro on validation set: 0.43478260869565216\n",
      "Confusion Matrix: \n",
      "[[10  2]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.91      0.83      0.87        12\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.45      0.42      0.43        13\n",
      "weighted avg       0.84      0.77      0.80        13\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.6153846153846154\n",
      "F1 micro on validation set: 0.6153846153846154\n",
      "F1 macro on validation set: 0.380952380952381\n",
      "Confusion Matrix: \n",
      "[[8 3]\n",
      " [2 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.80      0.73      0.76        11\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.40      0.36      0.38        13\n",
      "weighted avg       0.68      0.62      0.64        13\n",
      "\n",
      "Participant: cresh17\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.17647058823529413\n",
      "F1 micro on validation set: 0.17647058823529413\n",
      "F1 macro on validation set: 0.15384615384615383\n",
      "Confusion Matrix: \n",
      "[[2 1 0]\n",
      " [2 0 0]\n",
      " [6 5 1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.20      0.67      0.31         3\n",
      "        10.0       0.00      0.00      0.00         2\n",
      "        11.0       1.00      0.08      0.15        12\n",
      "\n",
      "    accuracy                           0.18        17\n",
      "   macro avg       0.40      0.25      0.15        17\n",
      "weighted avg       0.74      0.18      0.16        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.17647058823529413\n",
      "F1 micro on validation set: 0.17647058823529413\n",
      "F1 macro on validation set: 0.1346153846153846\n",
      "Confusion Matrix: \n",
      "[[2 1 0]\n",
      " [8 1 0]\n",
      " [3 2 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.15      0.67      0.25         3\n",
      "        10.0       0.25      0.11      0.15         9\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.18        17\n",
      "   macro avg       0.13      0.26      0.13        17\n",
      "weighted avg       0.16      0.18      0.13        17\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.6470588235294118\n",
      "F1 micro on validation set: 0.6470588235294118\n",
      "F1 macro on validation set: 0.6136363636363636\n",
      "Confusion Matrix: \n",
      "[[3 3]\n",
      " [3 8]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.50      0.50      0.50         6\n",
      "        11.0       0.73      0.73      0.73        11\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.61      0.61      0.61        17\n",
      "weighted avg       0.65      0.65      0.65        17\n",
      "\n",
      "Participant: cresh24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3157894736842105\n",
      "F1 micro on validation set: 0.3157894736842105\n",
      "F1 macro on validation set: 0.16\n",
      "Confusion Matrix: \n",
      "[[0 2 0]\n",
      " [6 6 0]\n",
      " [0 5 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.46      0.50      0.48        12\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.32        19\n",
      "   macro avg       0.15      0.17      0.16        19\n",
      "weighted avg       0.29      0.32      0.30        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.47368421052631576\n",
      "F1 micro on validation set: 0.47368421052631576\n",
      "F1 macro on validation set: 0.325\n",
      "Confusion Matrix: \n",
      "[[6 8 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       1.00      0.43      0.60        14\n",
      "        10.0       0.23      1.00      0.38         3\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.47        19\n",
      "   macro avg       0.41      0.48      0.33        19\n",
      "weighted avg       0.77      0.47      0.50        19\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.7368421052631579\n",
      "F1 micro on validation set: 0.7368421052631579\n",
      "F1 macro on validation set: 0.7246376811594203\n",
      "Confusion Matrix: \n",
      "[[5 4]\n",
      " [1 9]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.83      0.56      0.67         9\n",
      "        11.0       0.69      0.90      0.78        10\n",
      "\n",
      "    accuracy                           0.74        19\n",
      "   macro avg       0.76      0.73      0.72        19\n",
      "weighted avg       0.76      0.74      0.73        19\n",
      "\n",
      "Participant: cresh28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.3717948717948718\n",
      "Confusion Matrix: \n",
      "[[0 0 0]\n",
      " [1 2 2]\n",
      " [2 1 4]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "        10.0       0.67      0.40      0.50         5\n",
      "        11.0       0.67      0.57      0.62         7\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.44      0.32      0.37        12\n",
      "weighted avg       0.67      0.50      0.57        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[6 6]\n",
      " [0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.50      0.67        12\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.50      0.25      0.33        12\n",
      "weighted avg       1.00      0.50      0.67        12\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.6571428571428571\n",
      "Confusion Matrix: \n",
      "[[5 4]\n",
      " [0 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.56      0.71         9\n",
      "        11.0       0.43      1.00      0.60         3\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.71      0.78      0.66        12\n",
      "weighted avg       0.86      0.67      0.69        12\n",
      "\n",
      "Participant: cresh25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3333333333333333\n",
      "F1 micro on validation set: 0.3333333333333333\n",
      "F1 macro on validation set: 0.26495726495726496\n",
      "Confusion Matrix: \n",
      "[[2 4 3]\n",
      " [1 3 2]\n",
      " [0 0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.67      0.22      0.33         9\n",
      "        10.0       0.43      0.50      0.46         6\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.37      0.24      0.26        15\n",
      "weighted avg       0.57      0.33      0.38        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3333333333333333\n",
      "F1 micro on validation set: 0.3333333333333333\n",
      "F1 macro on validation set: 0.16666666666666666\n",
      "Confusion Matrix: \n",
      "[[0 9 0]\n",
      " [0 5 0]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         9\n",
      "        10.0       0.33      1.00      0.50         5\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.11      0.33      0.17        15\n",
      "weighted avg       0.11      0.33      0.17        15\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.8666666666666667\n",
      "F1 micro on validation set: 0.8666666666666667\n",
      "F1 macro on validation set: 0.4642857142857143\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.87      1.00      0.93        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.43      0.50      0.46        15\n",
      "weighted avg       0.75      0.87      0.80        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for participant in participant_list:\n",
    "    print(\"Participant: {}\\n\".format(participant))\n",
    "    df_train = pd.read_csv(\"../\" + df_file + \"_train_\" + participant + \".csv\")\n",
    "    df_val = pd.read_csv(\"../\" + df_file + \"_val_\" + participant + \".csv\")\n",
    "    # drop userid\n",
    "    df_train.drop('user_id', axis=1, inplace=True)\n",
    "    df_val.drop('user_id', axis=1, inplace=True)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # thermal comfort prediction    \n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_1_thermal, macro_rf_1_thermal, _ = model_validate(df_train, df_val, clf)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # light comfort prediction\n",
    "    # move light response to the end\n",
    "    df_aux = df_train.pop('light_cozie')\n",
    "    df_train['light_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val.pop('light_cozie')\n",
    "    df_val['light_cozie'] = df_aux\n",
    "        \n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_1_light, macro_rf_1_light, _ = model_validate(df_train, df_val, clf)\n",
    "        \n",
    "    ###########################################################################\n",
    "    # aural comfort prediction\n",
    "    # move aural response to the end\n",
    "    df_aux = df_train.pop('noise_cozie')\n",
    "    df_train['noise_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val.pop('noise_cozie')\n",
    "    df_val['noise_cozie'] = df_aux\n",
    "    \n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_1_aural, macro_rf_1_aural, _ = model_validate(df_train, df_val, clf)\n",
    "\n",
    "    # append all participant's responses for this feature set\n",
    "    list_micro_fs1_thermal[participant] = micro_rf_1_thermal\n",
    "    list_macro_fs1_thermal[participant] = macro_rf_1_thermal\n",
    "\n",
    "    list_micro_fs1_light[participant] = micro_rf_1_light\n",
    "    list_macro_fs1_light[participant] = macro_rf_1_light\n",
    "\n",
    "    list_micro_fs1_aural[participant] = micro_rf_1_aural\n",
    "    list_macro_fs1_aural[participant] = macro_rf_1_aural\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# FS2: Time + Sensing + Heart Rate + mbient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from: data-processed-preferences/2019-11-15_fs2\n"
     ]
    }
   ],
   "source": [
    "df_file = folder_path + file_date + \"_\" +  dataframes_names[1]\n",
    "print(\"Loading files from: {}\".format(df_file))\n",
    "\n",
    "list_micro_fs2_thermal = {}\n",
    "list_macro_fs2_thermal = {}\n",
    "\n",
    "list_micro_fs2_light = {}\n",
    "list_macro_fs2_light = {}\n",
    "\n",
    "list_micro_fs2_aural = {}\n",
    "list_macro_fs2_aural = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: cresh07\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5263157894736842\n",
      "F1 micro on validation set: 0.5263157894736842\n",
      "F1 macro on validation set: 0.2298850574712644\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 10  7]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.83      0.59      0.69        17\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53        19\n",
      "   macro avg       0.28      0.20      0.23        19\n",
      "weighted avg       0.75      0.53      0.62        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9473684210526315\n",
      "F1 micro on validation set: 0.9473684210526315\n",
      "F1 macro on validation set: 0.4864864864864865\n",
      "Confusion Matrix: \n",
      "[[18  1]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.95      0.97        19\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.50      0.47      0.49        19\n",
      "weighted avg       1.00      0.95      0.97        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9473684210526315\n",
      "F1 micro on validation set: 0.9473684210526315\n",
      "F1 macro on validation set: 0.4864864864864865\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        18\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.47      0.50      0.49        19\n",
      "weighted avg       0.90      0.95      0.92        19\n",
      "\n",
      "Participant: cresh10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5555555555555556\n",
      "F1 micro on validation set: 0.5555555555555556\n",
      "F1 macro on validation set: 0.30484330484330485\n",
      "Confusion Matrix: \n",
      "[[0 1 0]\n",
      " [0 9 4]\n",
      " [0 3 1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.69      0.69      0.69        13\n",
      "        11.0       0.20      0.25      0.22         4\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.30      0.31      0.30        18\n",
      "weighted avg       0.54      0.56      0.55        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.30303030303030304\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.83      1.00      0.91        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.28      0.33      0.30        18\n",
      "weighted avg       0.69      0.83      0.76        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.4000000000000001\n",
      "Confusion Matrix: \n",
      "[[12  5]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.92      0.71      0.80        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.46      0.35      0.40        18\n",
      "weighted avg       0.87      0.67      0.76        18\n",
      "\n",
      "Participant: cresh08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.42857142857142855\n",
      "Confusion Matrix: \n",
      "[[12  4]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.75      0.86        16\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.50      0.38      0.43        16\n",
      "weighted avg       1.00      0.75      0.86        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8125\n",
      "F1 micro on validation set: 0.8125\n",
      "F1 macro on validation set: 0.4482758620689655\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.81      1.00      0.90        13\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.41      0.50      0.45        16\n",
      "weighted avg       0.66      0.81      0.73        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9375\n",
      "F1 micro on validation set: 0.9375\n",
      "F1 macro on validation set: 0.4838709677419355\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        15\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.47      0.50      0.48        16\n",
      "weighted avg       0.88      0.94      0.91        16\n",
      "\n",
      "Participant: cresh12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.36274509803921573\n",
      "Confusion Matrix: \n",
      "[[0 3 0]\n",
      " [0 5 0]\n",
      " [0 7 5]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.33      1.00      0.50         5\n",
      "        11.0       1.00      0.42      0.59        12\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.44      0.47      0.36        20\n",
      "weighted avg       0.68      0.50      0.48        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9\n",
      "F1 micro on validation set: 0.9\n",
      "F1 macro on validation set: 0.4736842105263158\n",
      "Confusion Matrix: \n",
      "[[ 0  2]\n",
      " [ 0 18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      1.00      0.95        18\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.45      0.50      0.47        20\n",
      "weighted avg       0.81      0.90      0.85        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.9\n",
      "F1 micro on validation set: 0.9\n",
      "F1 macro on validation set: 0.803921568627451\n",
      "Confusion Matrix: \n",
      "[[16  0]\n",
      " [ 2  2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.89      1.00      0.94        16\n",
      "        11.0       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.94      0.75      0.80        20\n",
      "weighted avg       0.91      0.90      0.89        20\n",
      "\n",
      "Participant: cresh09\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.25\n",
      "F1 micro on validation set: 0.25\n",
      "F1 macro on validation set: 0.1693121693121693\n",
      "Confusion Matrix: \n",
      "[[ 0  0  1]\n",
      " [ 0  2 14]\n",
      " [ 0  0  3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       1.00      0.12      0.22        16\n",
      "        11.0       0.17      1.00      0.29         3\n",
      "\n",
      "    accuracy                           0.25        20\n",
      "   macro avg       0.39      0.38      0.17        20\n",
      "weighted avg       0.82      0.25      0.22        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.95\n",
      "F1 micro on validation set: 0.9500000000000001\n",
      "F1 macro on validation set: 0.48717948717948717\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        19\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.47      0.50      0.49        20\n",
      "weighted avg       0.90      0.95      0.93        20\n",
      "\n",
      "Participant: cresh06\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6326530612244898\n",
      "F1 micro on validation set: 0.6326530612244898\n",
      "F1 macro on validation set: 0.44949494949494945\n",
      "Confusion Matrix: \n",
      "[[15  5  0]\n",
      " [ 7 16  0]\n",
      " [ 2  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.62      0.75      0.68        20\n",
      "        10.0       0.64      0.70      0.67        23\n",
      "        11.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.63        49\n",
      "   macro avg       0.42      0.48      0.45        49\n",
      "weighted avg       0.56      0.63      0.59        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8367346938775511\n",
      "F1 micro on validation set: 0.8367346938775511\n",
      "F1 macro on validation set: 0.45555555555555555\n",
      "Confusion Matrix: \n",
      "[[ 0  8]\n",
      " [ 0 41]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         8\n",
      "        10.0       0.84      1.00      0.91        41\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.42      0.50      0.46        49\n",
      "weighted avg       0.70      0.84      0.76        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8571428571428571\n",
      "F1 micro on validation set: 0.8571428571428571\n",
      "F1 macro on validation set: 0.4615384615384615\n",
      "Confusion Matrix: \n",
      "[[42  0]\n",
      " [ 7  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.86      1.00      0.92        42\n",
      "        11.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.86        49\n",
      "   macro avg       0.43      0.50      0.46        49\n",
      "weighted avg       0.73      0.86      0.79        49\n",
      "\n",
      "Participant: cresh02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7083333333333334\n",
      "F1 micro on validation set: 0.7083333333333334\n",
      "F1 macro on validation set: 0.2833333333333333\n",
      "Confusion Matrix: \n",
      "[[ 0  1  2]\n",
      " [ 0  0  3]\n",
      " [ 0  1 17]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.00      0.00      0.00         3\n",
      "        11.0       0.77      0.94      0.85        18\n",
      "\n",
      "    accuracy                           0.71        24\n",
      "   macro avg       0.26      0.31      0.28        24\n",
      "weighted avg       0.58      0.71      0.64        24\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.4166666666666667\n",
      "F1 micro on validation set: 0.4166666666666667\n",
      "F1 macro on validation set: 0.35888888888888887\n",
      "Confusion Matrix: \n",
      "[[1 0 1]\n",
      " [3 7 2]\n",
      " [2 6 2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.17      0.50      0.25         2\n",
      "        10.0       0.54      0.58      0.56        12\n",
      "        11.0       0.40      0.20      0.27        10\n",
      "\n",
      "    accuracy                           0.42        24\n",
      "   macro avg       0.37      0.43      0.36        24\n",
      "weighted avg       0.45      0.42      0.41        24\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.5833333333333334\n",
      "F1 micro on validation set: 0.5833333333333334\n",
      "F1 macro on validation set: 0.5555555555555556\n",
      "Confusion Matrix: \n",
      "[[10  8]\n",
      " [ 2  4]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.83      0.56      0.67        18\n",
      "        11.0       0.33      0.67      0.44         6\n",
      "\n",
      "    accuracy                           0.58        24\n",
      "   macro avg       0.58      0.61      0.56        24\n",
      "weighted avg       0.71      0.58      0.61        24\n",
      "\n",
      "Participant: cresh13\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.8\n",
      "F1 micro on validation set: 0.8000000000000002\n",
      "F1 macro on validation set: 0.7333333333333334\n",
      "Confusion Matrix: \n",
      "[[ 3  2]\n",
      " [ 2 13]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.60      0.60      0.60         5\n",
      "        11.0       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.73      0.73      0.73        20\n",
      "weighted avg       0.80      0.80      0.80        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.3\n",
      "F1 micro on validation set: 0.3\n",
      "F1 macro on validation set: 0.2708333333333333\n",
      "Confusion Matrix: \n",
      "[[1 5]\n",
      " [9 5]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.10      0.17      0.12         6\n",
      "        10.0       0.50      0.36      0.42        14\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.30      0.26      0.27        20\n",
      "weighted avg       0.38      0.30      0.33        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.65\n",
      "F1 micro on validation set: 0.65\n",
      "F1 macro on validation set: 0.6491228070175439\n",
      "Confusion Matrix: \n",
      "[[6 6]\n",
      " [1 7]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.86      0.50      0.63        12\n",
      "        11.0       0.54      0.88      0.67         8\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.70      0.69      0.65        20\n",
      "weighted avg       0.73      0.65      0.65        20\n",
      "\n",
      "Participant: cresh15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9333333333333333\n",
      "F1 micro on validation set: 0.9333333333333333\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0 14]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.00      0.00      0.00         0\n",
      "        11.0       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.33      0.33      0.33        15\n",
      "weighted avg       0.93      0.93      0.93        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.06666666666666667\n",
      "F1 micro on validation set: 0.06666666666666667\n",
      "F1 macro on validation set: 0.0625\n",
      "Confusion Matrix: \n",
      "[[ 0 14]\n",
      " [ 0  1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00        14\n",
      "        10.0       0.07      1.00      0.12         1\n",
      "\n",
      "    accuracy                           0.07        15\n",
      "   macro avg       0.03      0.50      0.06        15\n",
      "weighted avg       0.00      0.07      0.01        15\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.8666666666666667\n",
      "F1 micro on validation set: 0.8666666666666667\n",
      "F1 macro on validation set: 0.7115384615384615\n",
      "Confusion Matrix: \n",
      "[[ 1  0]\n",
      " [ 2 12]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.33      1.00      0.50         1\n",
      "        11.0       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.67      0.93      0.71        15\n",
      "weighted avg       0.96      0.87      0.89        15\n",
      "\n",
      "Participant: cresh03\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.45454545454545453\n",
      "Confusion Matrix: \n",
      "[[15  3]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.83      0.91        18\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.50      0.42      0.45        18\n",
      "weighted avg       1.00      0.83      0.91        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.5555555555555556\n",
      "F1 micro on validation set: 0.5555555555555556\n",
      "F1 macro on validation set: 0.5694444444444445\n",
      "Confusion Matrix: \n",
      "[[3 0 0]\n",
      " [2 2 2]\n",
      " [0 4 5]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.60      1.00      0.75         3\n",
      "        10.0       0.33      0.33      0.33         6\n",
      "        11.0       0.71      0.56      0.63         9\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.55      0.63      0.57        18\n",
      "weighted avg       0.57      0.56      0.55        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9444444444444444\n",
      "F1 micro on validation set: 0.9444444444444444\n",
      "F1 macro on validation set: 0.4857142857142857\n",
      "Confusion Matrix: \n",
      "[[17  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.47      0.50      0.49        18\n",
      "weighted avg       0.89      0.94      0.92        18\n",
      "\n",
      "Participant: cresh14\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.5440900562851783\n",
      "Confusion Matrix: \n",
      "[[ 2  5]\n",
      " [ 4 16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.33      0.29      0.31         7\n",
      "        10.0       0.76      0.80      0.78        20\n",
      "\n",
      "    accuracy                           0.67        27\n",
      "   macro avg       0.55      0.54      0.54        27\n",
      "weighted avg       0.65      0.67      0.66        27\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[27]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           1.00        27\n",
      "   macro avg       1.00      1.00      1.00        27\n",
      "weighted avg       1.00      1.00      1.00        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9629629629629629\n",
      "F1 micro on validation set: 0.9629629629629629\n",
      "F1 macro on validation set: 0.49056603773584906\n",
      "Confusion Matrix: \n",
      "[[26  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      1.00      0.98        26\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        27\n",
      "   macro avg       0.48      0.50      0.49        27\n",
      "weighted avg       0.93      0.96      0.94        27\n",
      "\n",
      "Participant: cresh11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[8 0]\n",
      " [8 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.50      1.00      0.67         8\n",
      "        11.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.3125\n",
      "F1 micro on validation set: 0.3125\n",
      "F1 macro on validation set: 0.30980392156862746\n",
      "Confusion Matrix: \n",
      "[[2 2]\n",
      " [9 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.18      0.50      0.27         4\n",
      "        11.0       0.60      0.25      0.35        12\n",
      "\n",
      "    accuracy                           0.31        16\n",
      "   macro avg       0.39      0.38      0.31        16\n",
      "weighted avg       0.50      0.31      0.33        16\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.27777777777777773\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 15  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.71      1.00      0.83        15\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.24      0.33      0.28        21\n",
      "weighted avg       0.51      0.71      0.60        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9047619047619048\n",
      "F1 micro on validation set: 0.9047619047619048\n",
      "F1 macro on validation set: 0.47500000000000003\n",
      "Confusion Matrix: \n",
      "[[ 0  2]\n",
      " [ 0 19]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.45      0.50      0.48        21\n",
      "weighted avg       0.82      0.90      0.86        21\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "Participant: cresh01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6190476190476191\n",
      "F1 micro on validation set: 0.6190476190476191\n",
      "F1 macro on validation set: 0.25490196078431376\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 13  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.62      1.00      0.76        13\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.62        21\n",
      "   macro avg       0.21      0.33      0.25        21\n",
      "weighted avg       0.38      0.62      0.47        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.42857142857142855\n",
      "F1 micro on validation set: 0.42857142857142855\n",
      "F1 macro on validation set: 0.24603174603174605\n",
      "Confusion Matrix: \n",
      "[[ 1 10  0]\n",
      " [ 0  8  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       1.00      0.09      0.17        11\n",
      "        10.0       0.40      1.00      0.57         8\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.43        21\n",
      "   macro avg       0.47      0.36      0.25        21\n",
      "weighted avg       0.68      0.43      0.30        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9047619047619048\n",
      "F1 micro on validation set: 0.9047619047619048\n",
      "F1 macro on validation set: 0.47500000000000003\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.90      1.00      0.95        19\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.45      0.50      0.48        21\n",
      "weighted avg       0.82      0.90      0.86        21\n",
      "\n",
      "Participant: cresh04\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh22\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.25\n",
      "F1 micro on validation set: 0.25\n",
      "F1 macro on validation set: 0.2222222222222222\n",
      "Confusion Matrix: \n",
      "[[3 2 0]\n",
      " [2 1 3]\n",
      " [2 3 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.43      0.60      0.50         5\n",
      "        10.0       0.17      0.17      0.17         6\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.20      0.26      0.22        16\n",
      "weighted avg       0.20      0.25      0.22        16\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.875\n",
      "F1 micro on validation set: 0.875\n",
      "F1 macro on validation set: 0.4666666666666667\n",
      "Confusion Matrix: \n",
      "[[14  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      1.00      0.93        14\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.44      0.50      0.47        16\n",
      "weighted avg       0.77      0.88      0.82        16\n",
      "\n",
      "Participant: cresh16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.2777777777777778\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 20  1]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.74      0.95      0.83        21\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.25      0.32      0.28        28\n",
      "weighted avg       0.56      0.71      0.62        28\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Participant: cresh19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.625\n",
      "F1 micro on validation set: 0.625\n",
      "F1 macro on validation set: 0.25641025641025644\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.62      1.00      0.77        10\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.21      0.33      0.26        16\n",
      "weighted avg       0.39      0.62      0.48        16\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh21\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.5238095238095238\n",
      "F1 micro on validation set: 0.5238095238095238\n",
      "F1 macro on validation set: 0.49519230769230765\n",
      "Confusion Matrix: \n",
      "[[ 8  0]\n",
      " [10  3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.44      1.00      0.62         8\n",
      "        11.0       1.00      0.23      0.38        13\n",
      "\n",
      "    accuracy                           0.52        21\n",
      "   macro avg       0.72      0.62      0.50        21\n",
      "weighted avg       0.79      0.52      0.47        21\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9523809523809523\n",
      "F1 micro on validation set: 0.9523809523809523\n",
      "F1 macro on validation set: 0.4878048780487805\n",
      "Confusion Matrix: \n",
      "[[20  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.98        20\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.48      0.50      0.49        21\n",
      "weighted avg       0.91      0.95      0.93        21\n",
      "\n",
      "Participant: cresh26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8235294117647058\n",
      "F1 micro on validation set: 0.8235294117647058\n",
      "F1 macro on validation set: 0.3010752688172043\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0 14  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.82      1.00      0.90        14\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.27      0.33      0.30        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8235294117647058\n",
      "F1 micro on validation set: 0.8235294117647058\n",
      "F1 macro on validation set: 0.45161290322580644\n",
      "Confusion Matrix: \n",
      "[[14  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.82      1.00      0.90        14\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.41      0.50      0.45        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8823529411764706\n",
      "F1 micro on validation set: 0.8823529411764706\n",
      "F1 macro on validation set: 0.46875\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      1.00      0.94        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.44      0.50      0.47        17\n",
      "weighted avg       0.78      0.88      0.83        17\n",
      "\n",
      "Participant: cresh29\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Participant: cresh27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9166666666666666\n",
      "F1 micro on validation set: 0.9166666666666666\n",
      "F1 macro on validation set: 0.4782608695652174\n",
      "Confusion Matrix: \n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.92      1.00      0.96        11\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.6210526315789474\n",
      "Confusion Matrix: \n",
      "[[8 2]\n",
      " [1 1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.89      0.80      0.84        10\n",
      "        11.0       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.61      0.65      0.62        12\n",
      "weighted avg       0.80      0.75      0.77        12\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[12]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Participant: cresh23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.2666666666666667\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 12  3]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.80      0.80      0.80        15\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.27      0.27      0.27        18\n",
      "weighted avg       0.67      0.67      0.67        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7222222222222222\n",
      "F1 micro on validation set: 0.7222222222222222\n",
      "F1 macro on validation set: 0.27956989247311825\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 13  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.72      1.00      0.84        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.24      0.33      0.28        18\n",
      "weighted avg       0.52      0.72      0.61        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.4444444444444444\n",
      "F1 micro on validation set: 0.4444444444444444\n",
      "F1 macro on validation set: 0.30769230769230765\n",
      "Confusion Matrix: \n",
      "[[8 1]\n",
      " [9 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.47      0.89      0.62         9\n",
      "        11.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.44        18\n",
      "   macro avg       0.24      0.44      0.31        18\n",
      "weighted avg       0.24      0.44      0.31        18\n",
      "\n",
      "Participant: cresh20\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.7222222222222222\n",
      "F1 micro on validation set: 0.7222222222222222\n",
      "F1 macro on validation set: 0.41935483870967744\n",
      "Confusion Matrix: \n",
      "[[ 0  1]\n",
      " [ 4 13]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.46      0.38      0.42        18\n",
      "weighted avg       0.88      0.72      0.79        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.72\n",
      "F1 micro on validation set: 0.72\n",
      "F1 macro on validation set: 0.27906976744186046\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 18  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.72      1.00      0.84        18\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.72        25\n",
      "   macro avg       0.24      0.33      0.28        25\n",
      "weighted avg       0.52      0.72      0.60        25\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[25]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.92\n",
      "F1 micro on validation set: 0.92\n",
      "F1 macro on validation set: 0.4791666666666667\n",
      "Confusion Matrix: \n",
      "[[23  1]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      0.96      0.96        24\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        25\n",
      "   macro avg       0.48      0.48      0.48        25\n",
      "weighted avg       0.92      0.92      0.92        25\n",
      "\n",
      "Participant: cresh30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5384615384615384\n",
      "F1 micro on validation set: 0.5384615384615384\n",
      "F1 macro on validation set: 0.24561403508771926\n",
      "Confusion Matrix: \n",
      "[[0 1 1]\n",
      " [0 7 3]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.78      0.70      0.74        10\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.26      0.23      0.25        13\n",
      "weighted avg       0.60      0.54      0.57        13\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.7692307692307693\n",
      "F1 micro on validation set: 0.7692307692307693\n",
      "F1 macro on validation set: 0.43478260869565216\n",
      "Confusion Matrix: \n",
      "[[10  2]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.91      0.83      0.87        12\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.45      0.42      0.43        13\n",
      "weighted avg       0.84      0.77      0.80        13\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.5384615384615384\n",
      "F1 micro on validation set: 0.5384615384615384\n",
      "F1 macro on validation set: 0.35000000000000003\n",
      "Confusion Matrix: \n",
      "[[7 4]\n",
      " [2 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.78      0.64      0.70        11\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.39      0.32      0.35        13\n",
      "weighted avg       0.66      0.54      0.59        13\n",
      "\n",
      "Participant: cresh17\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.29411764705882354\n",
      "F1 micro on validation set: 0.29411764705882354\n",
      "F1 macro on validation set: 0.2545454545454546\n",
      "Confusion Matrix: \n",
      "[[2 1 0]\n",
      " [2 0 0]\n",
      " [4 5 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.25      0.67      0.36         3\n",
      "        10.0       0.00      0.00      0.00         2\n",
      "        11.0       1.00      0.25      0.40        12\n",
      "\n",
      "    accuracy                           0.29        17\n",
      "   macro avg       0.42      0.31      0.25        17\n",
      "weighted avg       0.75      0.29      0.35        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.17647058823529413\n",
      "F1 micro on validation set: 0.17647058823529413\n",
      "F1 macro on validation set: 0.1365079365079365\n",
      "Confusion Matrix: \n",
      "[[2 1 0]\n",
      " [8 1 0]\n",
      " [2 3 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.17      0.67      0.27         3\n",
      "        10.0       0.20      0.11      0.14         9\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.18        17\n",
      "   macro avg       0.12      0.26      0.14        17\n",
      "weighted avg       0.14      0.18      0.12        17\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.5294117647058824\n",
      "F1 micro on validation set: 0.5294117647058824\n",
      "F1 macro on validation set: 0.43333333333333335\n",
      "Confusion Matrix: \n",
      "[[1 5]\n",
      " [3 8]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.25      0.17      0.20         6\n",
      "        11.0       0.62      0.73      0.67        11\n",
      "\n",
      "    accuracy                           0.53        17\n",
      "   macro avg       0.43      0.45      0.43        17\n",
      "weighted avg       0.49      0.53      0.50        17\n",
      "\n",
      "Participant: cresh24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3684210526315789\n",
      "F1 micro on validation set: 0.3684210526315789\n",
      "F1 macro on validation set: 0.24074074074074073\n",
      "Confusion Matrix: \n",
      "[[1 1 0]\n",
      " [6 6 0]\n",
      " [0 5 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.14      0.50      0.22         2\n",
      "        10.0       0.50      0.50      0.50        12\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.37        19\n",
      "   macro avg       0.21      0.33      0.24        19\n",
      "weighted avg       0.33      0.37      0.34        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3157894736842105\n",
      "F1 micro on validation set: 0.3157894736842105\n",
      "F1 macro on validation set: 0.22291021671826625\n",
      "Confusion Matrix: \n",
      "[[ 3 11  0]\n",
      " [ 0  3  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       1.00      0.21      0.35        14\n",
      "        10.0       0.19      1.00      0.32         3\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.32        19\n",
      "   macro avg       0.40      0.40      0.22        19\n",
      "weighted avg       0.77      0.32      0.31        19\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.6842105263157895\n",
      "F1 micro on validation set: 0.6842105263157895\n",
      "F1 macro on validation set: 0.6607142857142857\n",
      "Confusion Matrix: \n",
      "[[4 5]\n",
      " [1 9]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.80      0.44      0.57         9\n",
      "        11.0       0.64      0.90      0.75        10\n",
      "\n",
      "    accuracy                           0.68        19\n",
      "   macro avg       0.72      0.67      0.66        19\n",
      "weighted avg       0.72      0.68      0.67        19\n",
      "\n",
      "Participant: cresh28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.5230769230769231\n",
      "Confusion Matrix: \n",
      "[[0 0 0]\n",
      " [0 4 1]\n",
      " [1 1 5]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "        10.0       0.80      0.80      0.80         5\n",
      "        11.0       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.54      0.50      0.52        12\n",
      "weighted avg       0.82      0.75      0.78        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.42857142857142855\n",
      "Confusion Matrix: \n",
      "[[9 3]\n",
      " [0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.75      0.86        12\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.50      0.38      0.43        12\n",
      "weighted avg       1.00      0.75      0.86        12\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.6571428571428571\n",
      "Confusion Matrix: \n",
      "[[5 4]\n",
      " [0 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.56      0.71         9\n",
      "        11.0       0.43      1.00      0.60         3\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.71      0.78      0.66        12\n",
      "weighted avg       0.86      0.67      0.69        12\n",
      "\n",
      "Participant: cresh25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.4666666666666667\n",
      "F1 micro on validation set: 0.4666666666666667\n",
      "F1 macro on validation set: 0.34432234432234426\n",
      "Confusion Matrix: \n",
      "[[4 4 1]\n",
      " [1 3 2]\n",
      " [0 0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.80      0.44      0.57         9\n",
      "        10.0       0.43      0.50      0.46         6\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.47        15\n",
      "   macro avg       0.41      0.31      0.34        15\n",
      "weighted avg       0.65      0.47      0.53        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3333333333333333\n",
      "F1 micro on validation set: 0.3333333333333333\n",
      "F1 macro on validation set: 0.16666666666666666\n",
      "Confusion Matrix: \n",
      "[[0 9 0]\n",
      " [0 5 0]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         9\n",
      "        10.0       0.33      1.00      0.50         5\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.11      0.33      0.17        15\n",
      "weighted avg       0.11      0.33      0.17        15\n",
      "\n",
      "Accuracy (f1 micro) on validation set: 0.8666666666666667\n",
      "F1 micro on validation set: 0.8666666666666667\n",
      "F1 macro on validation set: 0.4642857142857143\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.87      1.00      0.93        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.43      0.50      0.46        15\n",
      "weighted avg       0.75      0.87      0.80        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for participant in participant_list:\n",
    "    print(\"Participant: {}\\n\".format(participant))\n",
    "    df_train = pd.read_csv(\"../\" + df_file + \"_train_\" + participant + \".csv\")\n",
    "    df_val = pd.read_csv(\"../\" + df_file + \"_val_\" + participant + \".csv\")\n",
    "    # drop userid\n",
    "    df_train.drop('user_id', axis=1, inplace=True)\n",
    "    df_val.drop('user_id', axis=1, inplace=True)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # thermal comfort prediction    \n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_2_thermal, macro_rf_2_thermal, _ = model_validate(df_train, df_val, clf)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # light comfort prediction\n",
    "    # move light response to the end\n",
    "    df_aux = df_train.pop('light_cozie')\n",
    "    df_train['light_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val.pop('light_cozie')\n",
    "    df_val['light_cozie'] = df_aux\n",
    "        \n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_2_light, macro_rf_2_light, _ = model_validate(df_train, df_val, clf)\n",
    "        \n",
    "    ###########################################################################\n",
    "    # aural comfort prediction\n",
    "    # move aural response to the end\n",
    "    df_aux = df_train.pop('noise_cozie')\n",
    "    df_train['noise_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val.pop('noise_cozie')\n",
    "    df_val['noise_cozie'] = df_aux\n",
    "    \n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_2_aural, macro_rf_2_aural, _ = model_validate(df_train, df_val, clf)\n",
    "\n",
    "    # append all participant's responses for this feature set\n",
    "    list_micro_fs2_thermal[participant] = micro_rf_2_thermal\n",
    "    list_macro_fs2_thermal[participant] = macro_rf_2_thermal\n",
    "\n",
    "    list_micro_fs2_light[participant] = micro_rf_2_light\n",
    "    list_macro_fs2_light[participant] = macro_rf_2_light\n",
    "\n",
    "    list_micro_fs2_aural[participant] = micro_rf_2_aural\n",
    "    list_macro_fs2_aural[participant] = macro_rf_2_aural\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# FS3: Time + Sensing + Heart Rate + mbient + room + preference history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from: data-processed-preferences/2019-11-15_fs3\n"
     ]
    }
   ],
   "source": [
    "df_file = folder_path + file_date + \"_\" +  dataframes_names[2]\n",
    "print(\"Loading files from: {}\".format(df_file))\n",
    "\n",
    "list_micro_fs3_thermal = {}\n",
    "list_macro_fs3_thermal = {}\n",
    "\n",
    "list_micro_fs3_light = {}\n",
    "list_macro_fs3_light = {}\n",
    "\n",
    "list_micro_fs3_aural = {}\n",
    "list_macro_fs3_aural = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: cresh07\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5263157894736842\n",
      "F1 micro on validation set: 0.5263157894736842\n",
      "F1 macro on validation set: 0.2298850574712644\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 10  7]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.83      0.59      0.69        17\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53        19\n",
      "   macro avg       0.28      0.20      0.23        19\n",
      "weighted avg       0.75      0.53      0.62        19\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9473684210526315\n",
      "F1 micro on validation set: 0.9473684210526315\n",
      "F1 macro on validation set: 0.4864864864864865\n",
      "Confusion Matrix: \n",
      "[[18  1]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.95      0.97        19\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.50      0.47      0.49        19\n",
      "weighted avg       1.00      0.95      0.97        19\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9473684210526315\n",
      "F1 micro on validation set: 0.9473684210526315\n",
      "F1 macro on validation set: 0.4864864864864865\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        18\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.47      0.50      0.49        19\n",
      "weighted avg       0.90      0.95      0.92        19\n",
      "\n",
      "Participant: cresh10\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.4444444444444444\n",
      "F1 micro on validation set: 0.4444444444444444\n",
      "F1 macro on validation set: 0.30501089324618735\n",
      "Confusion Matrix: \n",
      "[[0 1 0]\n",
      " [0 4 9]\n",
      " [0 0 4]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.80      0.31      0.44        13\n",
      "        11.0       0.31      1.00      0.47         4\n",
      "\n",
      "    accuracy                           0.44        18\n",
      "   macro avg       0.37      0.44      0.31        18\n",
      "weighted avg       0.65      0.44      0.43        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.30303030303030304\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.83      1.00      0.91        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.28      0.33      0.30        18\n",
      "weighted avg       0.69      0.83      0.76        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.7777777777777778\n",
      "F1 micro on validation set: 0.7777777777777778\n",
      "F1 macro on validation set: 0.43749999999999994\n",
      "Confusion Matrix: \n",
      "[[14  3]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.93      0.82      0.87        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.47      0.41      0.44        18\n",
      "weighted avg       0.88      0.78      0.83        18\n",
      "\n",
      "Participant: cresh08\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.42857142857142855\n",
      "Confusion Matrix: \n",
      "[[12  4]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.75      0.86        16\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.50      0.38      0.43        16\n",
      "weighted avg       1.00      0.75      0.86        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8125\n",
      "F1 micro on validation set: 0.8125\n",
      "F1 macro on validation set: 0.4482758620689655\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.81      1.00      0.90        13\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.41      0.50      0.45        16\n",
      "weighted avg       0.66      0.81      0.73        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9375\n",
      "F1 micro on validation set: 0.9375\n",
      "F1 macro on validation set: 0.4838709677419355\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        15\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.47      0.50      0.48        16\n",
      "weighted avg       0.88      0.94      0.91        16\n",
      "\n",
      "Participant: cresh12\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7\n",
      "F1 micro on validation set: 0.7\n",
      "F1 macro on validation set: 0.49404761904761907\n",
      "Confusion Matrix: \n",
      "[[0 3 0]\n",
      " [0 5 0]\n",
      " [0 3 9]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.45      1.00      0.62         5\n",
      "        11.0       1.00      0.75      0.86        12\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.48      0.58      0.49        20\n",
      "weighted avg       0.71      0.70      0.67        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9\n",
      "F1 micro on validation set: 0.9\n",
      "F1 macro on validation set: 0.4736842105263158\n",
      "Confusion Matrix: \n",
      "[[ 0  2]\n",
      " [ 0 18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      1.00      0.95        18\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.45      0.50      0.47        20\n",
      "weighted avg       0.81      0.90      0.85        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.9\n",
      "F1 micro on validation set: 0.9\n",
      "F1 macro on validation set: 0.803921568627451\n",
      "Confusion Matrix: \n",
      "[[16  0]\n",
      " [ 2  2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.89      1.00      0.94        16\n",
      "        11.0       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.94      0.75      0.80        20\n",
      "weighted avg       0.91      0.90      0.89        20\n",
      "\n",
      "Participant: cresh09\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3\n",
      "F1 micro on validation set: 0.3\n",
      "F1 macro on validation set: 0.16000000000000003\n",
      "Confusion Matrix: \n",
      "[[ 0  0  1]\n",
      " [ 0  6 10]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.67      0.38      0.48        16\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.22      0.12      0.16        20\n",
      "weighted avg       0.53      0.30      0.38        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.95\n",
      "F1 micro on validation set: 0.9500000000000001\n",
      "F1 macro on validation set: 0.48717948717948717\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        19\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.47      0.50      0.49        20\n",
      "weighted avg       0.90      0.95      0.93        20\n",
      "\n",
      "Participant: cresh06\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6122448979591837\n",
      "F1 micro on validation set: 0.6122448979591837\n",
      "F1 macro on validation set: 0.6198830409356725\n",
      "Confusion Matrix: \n",
      "[[10 10  0]\n",
      " [ 6 17  0]\n",
      " [ 2  1  3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.56      0.50      0.53        20\n",
      "        10.0       0.61      0.74      0.67        23\n",
      "        11.0       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.61        49\n",
      "   macro avg       0.72      0.58      0.62        49\n",
      "weighted avg       0.63      0.61      0.61        49\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8367346938775511\n",
      "F1 micro on validation set: 0.8367346938775511\n",
      "F1 macro on validation set: 0.45555555555555555\n",
      "Confusion Matrix: \n",
      "[[ 0  8]\n",
      " [ 0 41]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         8\n",
      "        10.0       0.84      1.00      0.91        41\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.42      0.50      0.46        49\n",
      "weighted avg       0.70      0.84      0.76        49\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8571428571428571\n",
      "F1 micro on validation set: 0.8571428571428571\n",
      "F1 macro on validation set: 0.4615384615384615\n",
      "Confusion Matrix: \n",
      "[[42  0]\n",
      " [ 7  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.86      1.00      0.92        42\n",
      "        11.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.86        49\n",
      "   macro avg       0.43      0.50      0.46        49\n",
      "weighted avg       0.73      0.86      0.79        49\n",
      "\n",
      "Participant: cresh02\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7083333333333334\n",
      "F1 micro on validation set: 0.7083333333333334\n",
      "F1 macro on validation set: 0.2982456140350877\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0  0  3]\n",
      " [ 0  1 17]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.00      0.00      0.00         3\n",
      "        11.0       0.85      0.94      0.89        18\n",
      "\n",
      "    accuracy                           0.71        24\n",
      "   macro avg       0.28      0.31      0.30        24\n",
      "weighted avg       0.64      0.71      0.67        24\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.4583333333333333\n",
      "F1 micro on validation set: 0.4583333333333333\n",
      "F1 macro on validation set: 0.4069047619047619\n",
      "Confusion Matrix: \n",
      "[[1 0 1]\n",
      " [3 7 2]\n",
      " [1 6 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.20      0.50      0.29         2\n",
      "        10.0       0.54      0.58      0.56        12\n",
      "        11.0       0.50      0.30      0.37        10\n",
      "\n",
      "    accuracy                           0.46        24\n",
      "   macro avg       0.41      0.46      0.41        24\n",
      "weighted avg       0.49      0.46      0.46        24\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5833333333333334\n",
      "F1 micro on validation set: 0.5833333333333334\n",
      "F1 macro on validation set: 0.53125\n",
      "Confusion Matrix: \n",
      "[[11  7]\n",
      " [ 3  3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.79      0.61      0.69        18\n",
      "        11.0       0.30      0.50      0.37         6\n",
      "\n",
      "    accuracy                           0.58        24\n",
      "   macro avg       0.54      0.56      0.53        24\n",
      "weighted avg       0.66      0.58      0.61        24\n",
      "\n",
      "Participant: cresh13\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8\n",
      "F1 micro on validation set: 0.8000000000000002\n",
      "F1 macro on validation set: 0.7333333333333334\n",
      "Confusion Matrix: \n",
      "[[ 3  2]\n",
      " [ 2 13]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.60      0.60      0.60         5\n",
      "        11.0       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.73      0.73      0.73        20\n",
      "weighted avg       0.80      0.80      0.80        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.35\n",
      "F1 micro on validation set: 0.35\n",
      "F1 macro on validation set: 0.30666666666666664\n",
      "Confusion Matrix: \n",
      "[[1 5]\n",
      " [8 6]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.11      0.17      0.13         6\n",
      "        10.0       0.55      0.43      0.48        14\n",
      "\n",
      "    accuracy                           0.35        20\n",
      "   macro avg       0.33      0.30      0.31        20\n",
      "weighted avg       0.42      0.35      0.38        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.65\n",
      "F1 micro on validation set: 0.65\n",
      "F1 macro on validation set: 0.6491228070175439\n",
      "Confusion Matrix: \n",
      "[[6 6]\n",
      " [1 7]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.86      0.50      0.63        12\n",
      "        11.0       0.54      0.88      0.67         8\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.70      0.69      0.65        20\n",
      "weighted avg       0.73      0.65      0.65        20\n",
      "\n",
      "Participant: cresh15\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9333333333333333\n",
      "F1 micro on validation set: 0.9333333333333333\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0 14]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.00      0.00      0.00         0\n",
      "        11.0       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.33      0.33      0.33        15\n",
      "weighted avg       0.93      0.93      0.93        15\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.13333333333333333\n",
      "F1 micro on validation set: 0.13333333333333333\n",
      "F1 macro on validation set: 0.13333333333333333\n",
      "Confusion Matrix: \n",
      "[[ 1 13]\n",
      " [ 0  1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       1.00      0.07      0.13        14\n",
      "        10.0       0.07      1.00      0.13         1\n",
      "\n",
      "    accuracy                           0.13        15\n",
      "   macro avg       0.54      0.54      0.13        15\n",
      "weighted avg       0.94      0.13      0.13        15\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8666666666666667\n",
      "F1 micro on validation set: 0.8666666666666667\n",
      "F1 macro on validation set: 0.7115384615384615\n",
      "Confusion Matrix: \n",
      "[[ 1  0]\n",
      " [ 2 12]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.33      1.00      0.50         1\n",
      "        11.0       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.67      0.93      0.71        15\n",
      "weighted avg       0.96      0.87      0.89        15\n",
      "\n",
      "Participant: cresh03\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.45454545454545453\n",
      "Confusion Matrix: \n",
      "[[15  3]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.83      0.91        18\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.50      0.42      0.45        18\n",
      "weighted avg       1.00      0.83      0.91        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6111111111111112\n",
      "F1 micro on validation set: 0.6111111111111112\n",
      "F1 macro on validation set: 0.60650623885918\n",
      "Confusion Matrix: \n",
      "[[3 0 0]\n",
      " [2 2 2]\n",
      " [0 3 6]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.60      1.00      0.75         3\n",
      "        10.0       0.40      0.33      0.36         6\n",
      "        11.0       0.75      0.67      0.71         9\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.58      0.67      0.61        18\n",
      "weighted avg       0.61      0.61      0.60        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9444444444444444\n",
      "F1 micro on validation set: 0.9444444444444444\n",
      "F1 macro on validation set: 0.4857142857142857\n",
      "Confusion Matrix: \n",
      "[[17  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.47      0.50      0.49        18\n",
      "weighted avg       0.89      0.94      0.92        18\n",
      "\n",
      "Participant: cresh14\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5925925925925926\n",
      "F1 micro on validation set: 0.5925925925925926\n",
      "F1 macro on validation set: 0.49230769230769234\n",
      "Confusion Matrix: \n",
      "[[ 2  5]\n",
      " [ 6 14]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.25      0.29      0.27         7\n",
      "        10.0       0.74      0.70      0.72        20\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.49      0.49      0.49        27\n",
      "weighted avg       0.61      0.59      0.60        27\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[27]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           1.00        27\n",
      "   macro avg       1.00      1.00      1.00        27\n",
      "weighted avg       1.00      1.00      1.00        27\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9629629629629629\n",
      "F1 micro on validation set: 0.9629629629629629\n",
      "F1 macro on validation set: 0.49056603773584906\n",
      "Confusion Matrix: \n",
      "[[26  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      1.00      0.98        26\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        27\n",
      "   macro avg       0.48      0.50      0.49        27\n",
      "weighted avg       0.93      0.96      0.94        27\n",
      "\n",
      "Participant: cresh11\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[8 0]\n",
      " [8 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.50      1.00      0.67         8\n",
      "        11.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.3125\n",
      "F1 micro on validation set: 0.3125\n",
      "F1 macro on validation set: 0.30980392156862746\n",
      "Confusion Matrix: \n",
      "[[2 2]\n",
      " [9 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.18      0.50      0.27         4\n",
      "        11.0       0.60      0.25      0.35        12\n",
      "\n",
      "    accuracy                           0.31        16\n",
      "   macro avg       0.39      0.38      0.31        16\n",
      "weighted avg       0.50      0.31      0.33        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh05\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.27777777777777773\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 15  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.71      1.00      0.83        15\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.24      0.33      0.28        21\n",
      "weighted avg       0.51      0.71      0.60        21\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9047619047619048\n",
      "F1 micro on validation set: 0.9047619047619048\n",
      "F1 macro on validation set: 0.47500000000000003\n",
      "Confusion Matrix: \n",
      "[[ 0  2]\n",
      " [ 0 19]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.45      0.50      0.48        21\n",
      "weighted avg       0.82      0.90      0.86        21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "Participant: cresh01\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6190476190476191\n",
      "F1 micro on validation set: 0.6190476190476191\n",
      "F1 macro on validation set: 0.25490196078431376\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 13  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.62      1.00      0.76        13\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.62        21\n",
      "   macro avg       0.21      0.33      0.25        21\n",
      "weighted avg       0.38      0.62      0.47        21\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.42857142857142855\n",
      "F1 micro on validation set: 0.42857142857142855\n",
      "F1 macro on validation set: 0.24603174603174605\n",
      "Confusion Matrix: \n",
      "[[ 1 10  0]\n",
      " [ 0  8  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       1.00      0.09      0.17        11\n",
      "        10.0       0.40      1.00      0.57         8\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.43        21\n",
      "   macro avg       0.47      0.36      0.25        21\n",
      "weighted avg       0.68      0.43      0.30        21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9047619047619048\n",
      "F1 micro on validation set: 0.9047619047619048\n",
      "F1 macro on validation set: 0.47500000000000003\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.90      1.00      0.95        19\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.45      0.50      0.48        21\n",
      "weighted avg       0.82      0.90      0.86        21\n",
      "\n",
      "Participant: cresh04\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh22\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.25\n",
      "F1 micro on validation set: 0.25\n",
      "F1 macro on validation set: 0.21445221445221443\n",
      "Confusion Matrix: \n",
      "[[3 2 0]\n",
      " [2 1 3]\n",
      " [3 2 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.38      0.60      0.46         5\n",
      "        10.0       0.20      0.17      0.18         6\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.19      0.26      0.21        16\n",
      "weighted avg       0.19      0.25      0.21        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.875\n",
      "F1 micro on validation set: 0.875\n",
      "F1 macro on validation set: 0.4666666666666667\n",
      "Confusion Matrix: \n",
      "[[14  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      1.00      0.93        14\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.44      0.50      0.47        16\n",
      "weighted avg       0.77      0.88      0.82        16\n",
      "\n",
      "Participant: cresh16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.2777777777777778\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 20  1]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.74      0.95      0.83        21\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.25      0.32      0.28        28\n",
      "weighted avg       0.56      0.71      0.62        28\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Participant: cresh19\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.625\n",
      "F1 micro on validation set: 0.625\n",
      "F1 macro on validation set: 0.25641025641025644\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.62      1.00      0.77        10\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.21      0.33      0.26        16\n",
      "weighted avg       0.39      0.62      0.48        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5238095238095238\n",
      "F1 micro on validation set: 0.5238095238095238\n",
      "F1 macro on validation set: 0.49519230769230765\n",
      "Confusion Matrix: \n",
      "[[ 8  0]\n",
      " [10  3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.44      1.00      0.62         8\n",
      "        11.0       1.00      0.23      0.38        13\n",
      "\n",
      "    accuracy                           0.52        21\n",
      "   macro avg       0.72      0.62      0.50        21\n",
      "weighted avg       0.79      0.52      0.47        21\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9523809523809523\n",
      "F1 micro on validation set: 0.9523809523809523\n",
      "F1 macro on validation set: 0.4878048780487805\n",
      "Confusion Matrix: \n",
      "[[20  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.98        20\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.48      0.50      0.49        21\n",
      "weighted avg       0.91      0.95      0.93        21\n",
      "\n",
      "Participant: cresh26\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8235294117647058\n",
      "F1 micro on validation set: 0.8235294117647058\n",
      "F1 macro on validation set: 0.3010752688172043\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0 14  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.82      1.00      0.90        14\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.27      0.33      0.30        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8235294117647058\n",
      "F1 micro on validation set: 0.8235294117647058\n",
      "F1 macro on validation set: 0.45161290322580644\n",
      "Confusion Matrix: \n",
      "[[14  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.82      1.00      0.90        14\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.41      0.50      0.45        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8823529411764706\n",
      "F1 micro on validation set: 0.8823529411764706\n",
      "F1 macro on validation set: 0.46875\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      1.00      0.94        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.44      0.50      0.47        17\n",
      "weighted avg       0.78      0.88      0.83        17\n",
      "\n",
      "Participant: cresh29\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Participant: cresh27\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9166666666666666\n",
      "F1 micro on validation set: 0.9166666666666666\n",
      "F1 macro on validation set: 0.4782608695652174\n",
      "Confusion Matrix: \n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.92      1.00      0.96        11\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.6210526315789474\n",
      "Confusion Matrix: \n",
      "[[8 2]\n",
      " [1 1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.89      0.80      0.84        10\n",
      "        11.0       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.61      0.65      0.62        12\n",
      "weighted avg       0.80      0.75      0.77        12\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[12]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Participant: cresh23\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.2666666666666667\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 12  3]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.80      0.80      0.80        15\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.27      0.27      0.27        18\n",
      "weighted avg       0.67      0.67      0.67        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7222222222222222\n",
      "F1 micro on validation set: 0.7222222222222222\n",
      "F1 macro on validation set: 0.4091954022988506\n",
      "Confusion Matrix: \n",
      "[[ 1  2  0]\n",
      " [ 1 12  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.50      0.33      0.40         3\n",
      "        10.0       0.75      0.92      0.83        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.42      0.42      0.41        18\n",
      "weighted avg       0.62      0.72      0.66        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.3888888888888889\n",
      "F1 micro on validation set: 0.3888888888888889\n",
      "F1 macro on validation set: 0.28\n",
      "Confusion Matrix: \n",
      "[[7 2]\n",
      " [9 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.44      0.78      0.56         9\n",
      "        11.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.39        18\n",
      "   macro avg       0.22      0.39      0.28        18\n",
      "weighted avg       0.22      0.39      0.28        18\n",
      "\n",
      "Participant: cresh20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.7222222222222222\n",
      "F1 micro on validation set: 0.7222222222222222\n",
      "F1 macro on validation set: 0.41935483870967744\n",
      "Confusion Matrix: \n",
      "[[ 0  1]\n",
      " [ 4 13]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.46      0.38      0.42        18\n",
      "weighted avg       0.88      0.72      0.79        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.72\n",
      "F1 micro on validation set: 0.72\n",
      "F1 macro on validation set: 0.27906976744186046\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 18  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.72      1.00      0.84        18\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.72        25\n",
      "   macro avg       0.24      0.33      0.28        25\n",
      "weighted avg       0.52      0.72      0.60        25\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[25]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.92\n",
      "F1 micro on validation set: 0.92\n",
      "F1 macro on validation set: 0.4791666666666667\n",
      "Confusion Matrix: \n",
      "[[23  1]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      0.96      0.96        24\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        25\n",
      "   macro avg       0.48      0.48      0.48        25\n",
      "weighted avg       0.92      0.92      0.92        25\n",
      "\n",
      "Participant: cresh30\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5384615384615384\n",
      "F1 micro on validation set: 0.5384615384615384\n",
      "F1 macro on validation set: 0.24561403508771926\n",
      "Confusion Matrix: \n",
      "[[0 1 1]\n",
      " [0 7 3]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.78      0.70      0.74        10\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.26      0.23      0.25        13\n",
      "weighted avg       0.60      0.54      0.57        13\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.7692307692307693\n",
      "F1 micro on validation set: 0.7692307692307693\n",
      "F1 macro on validation set: 0.43478260869565216\n",
      "Confusion Matrix: \n",
      "[[10  2]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.91      0.83      0.87        12\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.45      0.42      0.43        13\n",
      "weighted avg       0.84      0.77      0.80        13\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5384615384615384\n",
      "F1 micro on validation set: 0.5384615384615384\n",
      "F1 macro on validation set: 0.35000000000000003\n",
      "Confusion Matrix: \n",
      "[[7 4]\n",
      " [2 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.78      0.64      0.70        11\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.39      0.32      0.35        13\n",
      "weighted avg       0.66      0.54      0.59        13\n",
      "\n",
      "Participant: cresh17\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5294117647058824\n",
      "F1 micro on validation set: 0.5294117647058824\n",
      "F1 macro on validation set: 0.42380952380952386\n",
      "Confusion Matrix: \n",
      "[[2 1 0]\n",
      " [1 0 1]\n",
      " [1 4 7]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.50      0.67      0.57         3\n",
      "        10.0       0.00      0.00      0.00         2\n",
      "        11.0       0.88      0.58      0.70        12\n",
      "\n",
      "    accuracy                           0.53        17\n",
      "   macro avg       0.46      0.42      0.42        17\n",
      "weighted avg       0.71      0.53      0.59        17\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.17647058823529413\n",
      "F1 micro on validation set: 0.17647058823529413\n",
      "F1 macro on validation set: 0.1346153846153846\n",
      "Confusion Matrix: \n",
      "[[2 1 0]\n",
      " [8 1 0]\n",
      " [3 2 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.15      0.67      0.25         3\n",
      "        10.0       0.25      0.11      0.15         9\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.18        17\n",
      "   macro avg       0.13      0.26      0.13        17\n",
      "weighted avg       0.16      0.18      0.13        17\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5882352941176471\n",
      "F1 micro on validation set: 0.5882352941176471\n",
      "F1 macro on validation set: 0.47111111111111115\n",
      "Confusion Matrix: \n",
      "[[1 5]\n",
      " [2 9]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.33      0.17      0.22         6\n",
      "        11.0       0.64      0.82      0.72        11\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.49      0.49      0.47        17\n",
      "weighted avg       0.53      0.59      0.54        17\n",
      "\n",
      "Participant: cresh24\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3684210526315789\n",
      "F1 micro on validation set: 0.3684210526315789\n",
      "F1 macro on validation set: 0.24074074074074073\n",
      "Confusion Matrix: \n",
      "[[1 1 0]\n",
      " [6 6 0]\n",
      " [0 5 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.14      0.50      0.22         2\n",
      "        10.0       0.50      0.50      0.50        12\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.37        19\n",
      "   macro avg       0.21      0.33      0.24        19\n",
      "weighted avg       0.33      0.37      0.34        19\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5263157894736842\n",
      "F1 micro on validation set: 0.5263157894736842\n",
      "F1 macro on validation set: 0.35555555555555557\n",
      "Confusion Matrix: \n",
      "[[7 7 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       1.00      0.50      0.67        14\n",
      "        10.0       0.25      1.00      0.40         3\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.53        19\n",
      "   macro avg       0.42      0.50      0.36        19\n",
      "weighted avg       0.78      0.53      0.55        19\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.7368421052631579\n",
      "F1 micro on validation set: 0.7368421052631579\n",
      "F1 macro on validation set: 0.7246376811594203\n",
      "Confusion Matrix: \n",
      "[[5 4]\n",
      " [1 9]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.83      0.56      0.67         9\n",
      "        11.0       0.69      0.90      0.78        10\n",
      "\n",
      "    accuracy                           0.74        19\n",
      "   macro avg       0.76      0.73      0.72        19\n",
      "weighted avg       0.76      0.74      0.73        19\n",
      "\n",
      "Participant: cresh28\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.5090909090909091\n",
      "Confusion Matrix: \n",
      "[[0 0 0]\n",
      " [1 4 0]\n",
      " [2 1 4]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "        10.0       0.80      0.80      0.80         5\n",
      "        11.0       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.60      0.46      0.51        12\n",
      "weighted avg       0.92      0.67      0.76        12\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[6 6]\n",
      " [0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.50      0.67        12\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.50      0.25      0.33        12\n",
      "weighted avg       1.00      0.50      0.67        12\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.9166666666666666\n",
      "F1 micro on validation set: 0.9166666666666666\n",
      "F1 macro on validation set: 0.8991596638655461\n",
      "Confusion Matrix: \n",
      "[[8 1]\n",
      " [0 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.89      0.94         9\n",
      "        11.0       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.88      0.94      0.90        12\n",
      "weighted avg       0.94      0.92      0.92        12\n",
      "\n",
      "Participant: cresh25\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'humidity_sensing'\n",
      " 'light_sensing' 'noise_sensing' 'temperature_sensing'\n",
      " 'temperature_mbient' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.4666666666666667\n",
      "F1 micro on validation set: 0.4666666666666667\n",
      "F1 macro on validation set: 0.34432234432234426\n",
      "Confusion Matrix: \n",
      "[[4 4 1]\n",
      " [1 3 2]\n",
      " [0 0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.80      0.44      0.57         9\n",
      "        10.0       0.43      0.50      0.46         6\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.47        15\n",
      "   macro avg       0.41      0.31      0.34        15\n",
      "weighted avg       0.65      0.47      0.53        15\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3333333333333333\n",
      "F1 micro on validation set: 0.3333333333333333\n",
      "F1 macro on validation set: 0.16666666666666666\n",
      "Confusion Matrix: \n",
      "[[0 9 0]\n",
      " [0 5 0]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         9\n",
      "        10.0       0.33      1.00      0.50         5\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.11      0.33      0.17        15\n",
      "weighted avg       0.11      0.33      0.17        15\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'humidity_sensing' 'light_sensing'\n",
      " 'noise_sensing' 'temperature_sensing' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8666666666666667\n",
      "F1 micro on validation set: 0.8666666666666667\n",
      "F1 macro on validation set: 0.4642857142857143\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.87      1.00      0.93        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.43      0.50      0.46        15\n",
      "weighted avg       0.75      0.87      0.80        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for participant in participant_list:\n",
    "    print(\"Participant: {}\\n\".format(participant))\n",
    "    df_train = pd.read_csv(\"../\" + df_file + \"_train_\" + participant + \".csv\")\n",
    "    df_val = pd.read_csv(\"../\" + df_file + \"_val_\" + participant + \".csv\")\n",
    "    # drop userid\n",
    "    df_train.drop('user_id', axis=1, inplace=True)\n",
    "    df_val.drop('user_id', axis=1, inplace=True)\n",
    "    # drop room\n",
    "    df_train.drop('room', axis=1, inplace=True)\n",
    "    df_val.drop('room', axis=1, inplace=True)\n",
    "\n",
    "    ###########################################################################\n",
    "    # thermal comfort prediction\n",
    "    df_train_thermal = df_train.copy()\n",
    "    df_val_thermal = df_val.copy()\n",
    "    \n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_dimmer', 'user_grouped_brighter', 'user_grouped_quieter', 'user_grouped_louder',\n",
    "                         'room_grouped_dimmer', 'room_grouped_brighter', 'room_grouped_quieter', 'room_grouped_louder']\n",
    "\n",
    "    df_train_thermal.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_thermal.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_thermal.columns.values)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_3_thermal, macro_rf_3_thermal, _ = model_validate(df_train_thermal, df_val_thermal, clf)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # light comfort prediction\n",
    "    df_train_light = df_train.copy()\n",
    "    df_val_light = df_val.copy()\n",
    "\n",
    "    # move light response to the end\n",
    "    df_aux = df_train_light.pop('light_cozie')\n",
    "    df_train_light['light_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val_light.pop('light_cozie')\n",
    "    df_val_light['light_cozie'] = df_aux\n",
    "\n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_cooler', 'user_grouped_warmer', 'user_grouped_quieter', 'user_grouped_louder',\n",
    "                         'room_grouped_cooler', 'room_grouped_warmer', 'room_grouped_quieter', 'room_grouped_louder']\n",
    "\n",
    "    df_train_light.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_light.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_light.columns.values)\n",
    "\n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_3_light, macro_rf_3_light, _ = model_validate(df_train_light, df_val_light, clf)\n",
    "        \n",
    "    ###########################################################################\n",
    "    # aural comfort prediction\n",
    "    df_train_aural = df_train.copy()\n",
    "    df_val_aural = df_val.copy()\n",
    "\n",
    "    # move aural response to the end\n",
    "    df_aux = df_train_aural.pop('noise_cozie')\n",
    "    df_train_aural['noise_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val_aural.pop('noise_cozie')\n",
    "    df_val_aural['noise_cozie'] = df_aux\n",
    "\n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_cooler', 'user_grouped_warmer', 'user_grouped_dimmer', 'user_grouped_brighter',\n",
    "                         'room_grouped_cooler', 'room_grouped_warmer', 'room_grouped_dimmer', 'room_grouped_brighter']\n",
    "\n",
    "    df_train_aural.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_aural.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_aural.columns.values)\n",
    "\n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_3_aural, macro_rf_3_aural, _ = model_validate(df_train_aural, df_val_aural, clf)\n",
    "\n",
    "    # append all participant's responses for this feature set\n",
    "    list_micro_fs3_thermal[participant] = micro_rf_3_thermal\n",
    "    list_macro_fs3_thermal[participant] = macro_rf_3_thermal\n",
    "\n",
    "    list_micro_fs3_light[participant] = micro_rf_3_light\n",
    "    list_macro_fs3_light[participant] = macro_rf_3_light\n",
    "\n",
    "    list_micro_fs3_aural[participant] = micro_rf_3_aural\n",
    "    list_macro_fs3_aural[participant] = macro_rf_3_aural\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# FS4: Time + Heart Rate + mbient + room + preference history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from: data-processed-preferences/2019-11-15_fs4\n"
     ]
    }
   ],
   "source": [
    "df_file = folder_path + file_date + \"_\" +  dataframes_names[3]\n",
    "print(\"Loading files from: {}\".format(df_file))\n",
    "\n",
    "list_micro_fs4_thermal = {}\n",
    "list_macro_fs4_thermal = {}\n",
    "\n",
    "list_micro_fs4_light = {}\n",
    "list_macro_fs4_light = {}\n",
    "\n",
    "list_micro_fs4_aural = {}\n",
    "list_macro_fs4_aural = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: cresh07\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6842105263157895\n",
      "F1 micro on validation set: 0.6842105263157895\n",
      "F1 macro on validation set: 0.2708333333333333\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 13  4]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.87      0.76      0.81        17\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.68        19\n",
      "   macro avg       0.29      0.25      0.27        19\n",
      "weighted avg       0.78      0.68      0.73        19\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[19]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        19\n",
      "   macro avg       1.00      1.00      1.00        19\n",
      "weighted avg       1.00      1.00      1.00        19\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9473684210526315\n",
      "F1 micro on validation set: 0.9473684210526315\n",
      "F1 macro on validation set: 0.4864864864864865\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        18\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.47      0.50      0.49        19\n",
      "weighted avg       0.90      0.95      0.92        19\n",
      "\n",
      "Participant: cresh10\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6111111111111112\n",
      "F1 micro on validation set: 0.6111111111111112\n",
      "F1 macro on validation set: 0.39627039627039634\n",
      "Confusion Matrix: \n",
      "[[0 0 1]\n",
      " [0 8 5]\n",
      " [0 1 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.89      0.62      0.73        13\n",
      "        11.0       0.33      0.75      0.46         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.41      0.46      0.40        18\n",
      "weighted avg       0.72      0.61      0.63        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.30303030303030304\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.83      1.00      0.91        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.28      0.33      0.30        18\n",
      "weighted avg       0.69      0.83      0.76        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.7777777777777778\n",
      "F1 micro on validation set: 0.7777777777777778\n",
      "F1 macro on validation set: 0.43749999999999994\n",
      "Confusion Matrix: \n",
      "[[14  3]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.93      0.82      0.87        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.47      0.41      0.44        18\n",
      "weighted avg       0.88      0.78      0.83        18\n",
      "\n",
      "Participant: cresh08\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.42857142857142855\n",
      "Confusion Matrix: \n",
      "[[12  4]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.75      0.86        16\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.50      0.38      0.43        16\n",
      "weighted avg       1.00      0.75      0.86        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8125\n",
      "F1 micro on validation set: 0.8125\n",
      "F1 macro on validation set: 0.4482758620689655\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.81      1.00      0.90        13\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.41      0.50      0.45        16\n",
      "weighted avg       0.66      0.81      0.73        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9375\n",
      "F1 micro on validation set: 0.9375\n",
      "F1 macro on validation set: 0.4838709677419355\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        15\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.47      0.50      0.48        16\n",
      "weighted avg       0.88      0.94      0.91        16\n",
      "\n",
      "Participant: cresh12\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7\n",
      "F1 micro on validation set: 0.7\n",
      "F1 macro on validation set: 0.49404761904761907\n",
      "Confusion Matrix: \n",
      "[[0 3 0]\n",
      " [0 5 0]\n",
      " [0 3 9]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.45      1.00      0.62         5\n",
      "        11.0       1.00      0.75      0.86        12\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.48      0.58      0.49        20\n",
      "weighted avg       0.71      0.70      0.67        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9\n",
      "F1 micro on validation set: 0.9\n",
      "F1 macro on validation set: 0.4736842105263158\n",
      "Confusion Matrix: \n",
      "[[ 0  2]\n",
      " [ 0 18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      1.00      0.95        18\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.45      0.50      0.47        20\n",
      "weighted avg       0.81      0.90      0.85        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.85\n",
      "F1 micro on validation set: 0.85\n",
      "F1 macro on validation set: 0.6571428571428571\n",
      "Confusion Matrix: \n",
      "[[16  0]\n",
      " [ 3  1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.84      1.00      0.91        16\n",
      "        11.0       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.92      0.62      0.66        20\n",
      "weighted avg       0.87      0.85      0.81        20\n",
      "\n",
      "Participant: cresh09\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.4\n",
      "F1 micro on validation set: 0.4000000000000001\n",
      "F1 macro on validation set: 0.25555555555555554\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0  6 10]\n",
      " [ 0  1  2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.75      0.38      0.50        16\n",
      "        11.0       0.17      0.67      0.27         3\n",
      "\n",
      "    accuracy                           0.40        20\n",
      "   macro avg       0.31      0.35      0.26        20\n",
      "weighted avg       0.62      0.40      0.44        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.95\n",
      "F1 micro on validation set: 0.9500000000000001\n",
      "F1 macro on validation set: 0.48717948717948717\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        19\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.47      0.50      0.49        20\n",
      "weighted avg       0.90      0.95      0.93        20\n",
      "\n",
      "Participant: cresh06\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5102040816326531\n",
      "F1 micro on validation set: 0.5102040816326531\n",
      "F1 macro on validation set: 0.3505886147395581\n",
      "Confusion Matrix: \n",
      "[[ 8 12  0]\n",
      " [ 6 17  0]\n",
      " [ 5  1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.42      0.40      0.41        20\n",
      "        10.0       0.57      0.74      0.64        23\n",
      "        11.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.51        49\n",
      "   macro avg       0.33      0.38      0.35        49\n",
      "weighted avg       0.44      0.51      0.47        49\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8367346938775511\n",
      "F1 micro on validation set: 0.8367346938775511\n",
      "F1 macro on validation set: 0.45555555555555555\n",
      "Confusion Matrix: \n",
      "[[ 0  8]\n",
      " [ 0 41]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         8\n",
      "        10.0       0.84      1.00      0.91        41\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.42      0.50      0.46        49\n",
      "weighted avg       0.70      0.84      0.76        49\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8571428571428571\n",
      "F1 micro on validation set: 0.8571428571428571\n",
      "F1 macro on validation set: 0.4615384615384615\n",
      "Confusion Matrix: \n",
      "[[42  0]\n",
      " [ 7  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.86      1.00      0.92        42\n",
      "        11.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.86        49\n",
      "   macro avg       0.43      0.50      0.46        49\n",
      "weighted avg       0.73      0.86      0.79        49\n",
      "\n",
      "Participant: cresh02\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.35185185185185186\n",
      "Confusion Matrix: \n",
      "[[ 0  2  1]\n",
      " [ 0  1  2]\n",
      " [ 0  3 15]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.17      0.33      0.22         3\n",
      "        11.0       0.83      0.83      0.83        18\n",
      "\n",
      "    accuracy                           0.67        24\n",
      "   macro avg       0.33      0.39      0.35        24\n",
      "weighted avg       0.65      0.67      0.65        24\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5416666666666666\n",
      "F1 micro on validation set: 0.5416666666666666\n",
      "F1 macro on validation set: 0.5177133655394525\n",
      "Confusion Matrix: \n",
      "[[2 0 0]\n",
      " [3 7 2]\n",
      " [2 4 4]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.29      1.00      0.44         2\n",
      "        10.0       0.64      0.58      0.61        12\n",
      "        11.0       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.54        24\n",
      "   macro avg       0.53      0.66      0.52        24\n",
      "weighted avg       0.62      0.54      0.55        24\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.625\n",
      "F1 micro on validation set: 0.625\n",
      "F1 macro on validation set: 0.5636363636363636\n",
      "Confusion Matrix: \n",
      "[[12  6]\n",
      " [ 3  3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.80      0.67      0.73        18\n",
      "        11.0       0.33      0.50      0.40         6\n",
      "\n",
      "    accuracy                           0.62        24\n",
      "   macro avg       0.57      0.58      0.56        24\n",
      "weighted avg       0.68      0.62      0.65        24\n",
      "\n",
      "Participant: cresh13\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.6865203761755486\n",
      "Confusion Matrix: \n",
      "[[ 3  2]\n",
      " [ 3 12]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.50      0.60      0.55         5\n",
      "        11.0       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.68      0.70      0.69        20\n",
      "weighted avg       0.77      0.75      0.76        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.25\n",
      "F1 micro on validation set: 0.25\n",
      "F1 macro on validation set: 0.24812030075187969\n",
      "Confusion Matrix: \n",
      "[[ 2  4]\n",
      " [11  3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.15      0.33      0.21         6\n",
      "        10.0       0.43      0.21      0.29        14\n",
      "\n",
      "    accuracy                           0.25        20\n",
      "   macro avg       0.29      0.27      0.25        20\n",
      "weighted avg       0.35      0.25      0.26        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.7\n",
      "F1 micro on validation set: 0.7\n",
      "F1 macro on validation set: 0.7000000000000001\n",
      "Confusion Matrix: \n",
      "[[7 5]\n",
      " [1 7]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      0.58      0.70        12\n",
      "        11.0       0.58      0.88      0.70         8\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.73      0.73      0.70        20\n",
      "weighted avg       0.76      0.70      0.70        20\n",
      "\n",
      "Participant: cresh15\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9333333333333333\n",
      "F1 micro on validation set: 0.9333333333333333\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0 14]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.00      0.00      0.00         0\n",
      "        11.0       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.33      0.33      0.33        15\n",
      "weighted avg       0.93      0.93      0.93        15\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.13333333333333333\n",
      "F1 micro on validation set: 0.13333333333333333\n",
      "F1 macro on validation set: 0.13333333333333333\n",
      "Confusion Matrix: \n",
      "[[ 1 13]\n",
      " [ 0  1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       1.00      0.07      0.13        14\n",
      "        10.0       0.07      1.00      0.13         1\n",
      "\n",
      "    accuracy                           0.13        15\n",
      "   macro avg       0.54      0.54      0.13        15\n",
      "weighted avg       0.94      0.13      0.13        15\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.4\n",
      "F1 micro on validation set: 0.4000000000000001\n",
      "F1 macro on validation set: 0.354066985645933\n",
      "Confusion Matrix: \n",
      "[[1 0]\n",
      " [9 5]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.10      1.00      0.18         1\n",
      "        11.0       1.00      0.36      0.53        14\n",
      "\n",
      "    accuracy                           0.40        15\n",
      "   macro avg       0.55      0.68      0.35        15\n",
      "weighted avg       0.94      0.40      0.50        15\n",
      "\n",
      "Participant: cresh03\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9444444444444444\n",
      "F1 micro on validation set: 0.9444444444444444\n",
      "F1 macro on validation set: 0.4857142857142857\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.94      0.97        18\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.50      0.47      0.49        18\n",
      "weighted avg       1.00      0.94      0.97        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6111111111111112\n",
      "F1 micro on validation set: 0.6111111111111112\n",
      "F1 macro on validation set: 0.60650623885918\n",
      "Confusion Matrix: \n",
      "[[3 0 0]\n",
      " [2 2 2]\n",
      " [0 3 6]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.60      1.00      0.75         3\n",
      "        10.0       0.40      0.33      0.36         6\n",
      "        11.0       0.75      0.67      0.71         9\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.58      0.67      0.61        18\n",
      "weighted avg       0.61      0.61      0.60        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9444444444444444\n",
      "F1 micro on validation set: 0.9444444444444444\n",
      "F1 macro on validation set: 0.4857142857142857\n",
      "Confusion Matrix: \n",
      "[[17  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.47      0.50      0.49        18\n",
      "weighted avg       0.89      0.94      0.92        18\n",
      "\n",
      "Participant: cresh14\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.4862579281183932\n",
      "Confusion Matrix: \n",
      "[[ 1  6]\n",
      " [ 3 17]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.25      0.14      0.18         7\n",
      "        10.0       0.74      0.85      0.79        20\n",
      "\n",
      "    accuracy                           0.67        27\n",
      "   macro avg       0.49      0.50      0.49        27\n",
      "weighted avg       0.61      0.67      0.63        27\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[27]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           1.00        27\n",
      "   macro avg       1.00      1.00      1.00        27\n",
      "weighted avg       1.00      1.00      1.00        27\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9629629629629629\n",
      "F1 micro on validation set: 0.9629629629629629\n",
      "F1 macro on validation set: 0.49056603773584906\n",
      "Confusion Matrix: \n",
      "[[26  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      1.00      0.98        26\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        27\n",
      "   macro avg       0.48      0.50      0.49        27\n",
      "weighted avg       0.93      0.96      0.94        27\n",
      "\n",
      "Participant: cresh11\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[8 0]\n",
      " [8 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.50      1.00      0.67         8\n",
      "        11.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.25\n",
      "F1 micro on validation set: 0.25\n",
      "F1 macro on validation set: 0.25\n",
      "Confusion Matrix: \n",
      "[[ 2  2]\n",
      " [10  2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.17      0.50      0.25         4\n",
      "        11.0       0.50      0.17      0.25        12\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.33      0.33      0.25        16\n",
      "weighted avg       0.42      0.25      0.25        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh05\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.27777777777777773\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 15  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.71      1.00      0.83        15\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.24      0.33      0.28        21\n",
      "weighted avg       0.51      0.71      0.60        21\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9047619047619048\n",
      "F1 micro on validation set: 0.9047619047619048\n",
      "F1 macro on validation set: 0.47500000000000003\n",
      "Confusion Matrix: \n",
      "[[ 0  2]\n",
      " [ 0 19]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.45      0.50      0.48        21\n",
      "weighted avg       0.82      0.90      0.86        21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "Participant: cresh01\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6190476190476191\n",
      "F1 micro on validation set: 0.6190476190476191\n",
      "F1 macro on validation set: 0.25490196078431376\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 13  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.62      1.00      0.76        13\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.62        21\n",
      "   macro avg       0.21      0.33      0.25        21\n",
      "weighted avg       0.38      0.62      0.47        21\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.4254510921177588\n",
      "Confusion Matrix: \n",
      "[[11  0  0]\n",
      " [ 5  3  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.69      1.00      0.81        11\n",
      "        10.0       0.60      0.38      0.46         8\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.67        21\n",
      "   macro avg       0.43      0.46      0.43        21\n",
      "weighted avg       0.59      0.67      0.60        21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9047619047619048\n",
      "F1 micro on validation set: 0.9047619047619048\n",
      "F1 macro on validation set: 0.47500000000000003\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.90      1.00      0.95        19\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.45      0.50      0.48        21\n",
      "weighted avg       0.82      0.90      0.86        21\n",
      "\n",
      "Participant: cresh04\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh22\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.41269841269841273\n",
      "Confusion Matrix: \n",
      "[[4 1 0]\n",
      " [1 4 1]\n",
      " [2 3 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.57      0.80      0.67         5\n",
      "        10.0       0.50      0.67      0.57         6\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.36      0.49      0.41        16\n",
      "weighted avg       0.37      0.50      0.42        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.875\n",
      "F1 micro on validation set: 0.875\n",
      "F1 macro on validation set: 0.4666666666666667\n",
      "Confusion Matrix: \n",
      "[[14  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      1.00      0.93        14\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.44      0.50      0.47        16\n",
      "weighted avg       0.77      0.88      0.82        16\n",
      "\n",
      "Participant: cresh16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.2777777777777778\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 20  1]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.74      0.95      0.83        21\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.25      0.32      0.28        28\n",
      "weighted avg       0.56      0.71      0.62        28\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Participant: cresh19\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.625\n",
      "F1 micro on validation set: 0.625\n",
      "F1 macro on validation set: 0.25641025641025644\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.62      1.00      0.77        10\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.21      0.33      0.26        16\n",
      "weighted avg       0.39      0.62      0.48        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.47619047619047616\n",
      "F1 micro on validation set: 0.47619047619047616\n",
      "F1 macro on validation set: 0.42962962962962964\n",
      "Confusion Matrix: \n",
      "[[ 8  0]\n",
      " [11  2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.42      1.00      0.59         8\n",
      "        11.0       1.00      0.15      0.27        13\n",
      "\n",
      "    accuracy                           0.48        21\n",
      "   macro avg       0.71      0.58      0.43        21\n",
      "weighted avg       0.78      0.48      0.39        21\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9523809523809523\n",
      "F1 micro on validation set: 0.9523809523809523\n",
      "F1 macro on validation set: 0.4878048780487805\n",
      "Confusion Matrix: \n",
      "[[20  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.98        20\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.48      0.50      0.49        21\n",
      "weighted avg       0.91      0.95      0.93        21\n",
      "\n",
      "Participant: cresh26\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7647058823529411\n",
      "F1 micro on validation set: 0.7647058823529412\n",
      "F1 macro on validation set: 0.28888888888888886\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 1 13  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.81      0.93      0.87        14\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.27      0.31      0.29        17\n",
      "weighted avg       0.67      0.76      0.71        17\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8235294117647058\n",
      "F1 micro on validation set: 0.8235294117647058\n",
      "F1 macro on validation set: 0.45161290322580644\n",
      "Confusion Matrix: \n",
      "[[14  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.82      1.00      0.90        14\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.41      0.50      0.45        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8823529411764706\n",
      "F1 micro on validation set: 0.8823529411764706\n",
      "F1 macro on validation set: 0.46875\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      1.00      0.94        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.44      0.50      0.47        17\n",
      "weighted avg       0.78      0.88      0.83        17\n",
      "\n",
      "Participant: cresh29\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Participant: cresh27\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9166666666666666\n",
      "F1 micro on validation set: 0.9166666666666666\n",
      "F1 macro on validation set: 0.4782608695652174\n",
      "Confusion Matrix: \n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.92      1.00      0.96        11\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.5555555555555555\n",
      "Confusion Matrix: \n",
      "[[7 3]\n",
      " [1 1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      0.70      0.78        10\n",
      "        11.0       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.56      0.60      0.56        12\n",
      "weighted avg       0.77      0.67      0.70        12\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9166666666666666\n",
      "F1 micro on validation set: 0.9166666666666666\n",
      "F1 macro on validation set: 0.4782608695652174\n",
      "Confusion Matrix: \n",
      "[[11  1]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.92      0.96        12\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "Participant: cresh23\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7777777777777778\n",
      "F1 micro on validation set: 0.7777777777777778\n",
      "F1 macro on validation set: 0.29166666666666663\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 14  1]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.82      0.93      0.87        15\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.27      0.31      0.29        18\n",
      "weighted avg       0.69      0.78      0.73        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7222222222222222\n",
      "F1 micro on validation set: 0.7222222222222222\n",
      "F1 macro on validation set: 0.27956989247311825\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 13  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.72      1.00      0.84        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.24      0.33      0.28        18\n",
      "weighted avg       0.52      0.72      0.61        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.4444444444444444\n",
      "F1 micro on validation set: 0.4444444444444444\n",
      "F1 macro on validation set: 0.30769230769230765\n",
      "Confusion Matrix: \n",
      "[[8 1]\n",
      " [9 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.47      0.89      0.62         9\n",
      "        11.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.44        18\n",
      "   macro avg       0.24      0.44      0.31        18\n",
      "weighted avg       0.24      0.44      0.31        18\n",
      "\n",
      "Participant: cresh20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.2777777777777778\n",
      "F1 micro on validation set: 0.2777777777777778\n",
      "F1 macro on validation set: 0.17826617826617827\n",
      "Confusion Matrix: \n",
      "[[ 1  0  0]\n",
      " [11  4  2]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.08      1.00      0.15         1\n",
      "        10.0       1.00      0.24      0.38        17\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.28        18\n",
      "   macro avg       0.36      0.41      0.18        18\n",
      "weighted avg       0.95      0.28      0.37        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9444444444444444\n",
      "F1 micro on validation set: 0.9444444444444444\n",
      "F1 macro on validation set: 0.4857142857142857\n",
      "Confusion Matrix: \n",
      "[[ 0  0]\n",
      " [ 1 17]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "        10.0       1.00      0.94      0.97        18\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.50      0.47      0.49        18\n",
      "weighted avg       1.00      0.94      0.97        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.72\n",
      "F1 micro on validation set: 0.72\n",
      "F1 macro on validation set: 0.27906976744186046\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 18  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.72      1.00      0.84        18\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.72        25\n",
      "   macro avg       0.24      0.33      0.28        25\n",
      "weighted avg       0.52      0.72      0.60        25\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[25]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.92\n",
      "F1 micro on validation set: 0.92\n",
      "F1 macro on validation set: 0.4791666666666667\n",
      "Confusion Matrix: \n",
      "[[23  1]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      0.96      0.96        24\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        25\n",
      "   macro avg       0.48      0.48      0.48        25\n",
      "weighted avg       0.92      0.92      0.92        25\n",
      "\n",
      "Participant: cresh30\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6923076923076923\n",
      "F1 micro on validation set: 0.6923076923076923\n",
      "F1 macro on validation set: 0.28571428571428575\n",
      "Confusion Matrix: \n",
      "[[0 1 1]\n",
      " [0 9 1]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.82      0.90      0.86        10\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.27      0.30      0.29        13\n",
      "weighted avg       0.63      0.69      0.66        13\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8461538461538461\n",
      "F1 micro on validation set: 0.8461538461538461\n",
      "F1 macro on validation set: 0.4583333333333333\n",
      "Confusion Matrix: \n",
      "[[11  1]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.92      0.92      0.92        12\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.46      0.46      0.46        13\n",
      "weighted avg       0.85      0.85      0.85        13\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6923076923076923\n",
      "F1 micro on validation set: 0.6923076923076923\n",
      "F1 macro on validation set: 0.4090909090909091\n",
      "Confusion Matrix: \n",
      "[[9 2]\n",
      " [2 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.82      0.82      0.82        11\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.41      0.41      0.41        13\n",
      "weighted avg       0.69      0.69      0.69        13\n",
      "\n",
      "Participant: cresh17\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6470588235294118\n",
      "F1 micro on validation set: 0.6470588235294118\n",
      "F1 macro on validation set: 0.3731884057971014\n",
      "Confusion Matrix: \n",
      "[[ 1  1  1]\n",
      " [ 2  0  0]\n",
      " [ 2  0 10]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.20      0.33      0.25         3\n",
      "        10.0       0.00      0.00      0.00         2\n",
      "        11.0       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.37      0.39      0.37        17\n",
      "weighted avg       0.68      0.65      0.66        17\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.17647058823529413\n",
      "F1 micro on validation set: 0.17647058823529413\n",
      "F1 macro on validation set: 0.1365079365079365\n",
      "Confusion Matrix: \n",
      "[[2 1 0]\n",
      " [8 1 0]\n",
      " [2 3 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.17      0.67      0.27         3\n",
      "        10.0       0.20      0.11      0.14         9\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.18        17\n",
      "   macro avg       0.12      0.26      0.14        17\n",
      "weighted avg       0.14      0.18      0.12        17\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6470588235294118\n",
      "F1 micro on validation set: 0.6470588235294118\n",
      "F1 macro on validation set: 0.3928571428571429\n",
      "Confusion Matrix: \n",
      "[[ 0  6]\n",
      " [ 0 11]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.00      0.00      0.00         6\n",
      "        11.0       0.65      1.00      0.79        11\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.32      0.50      0.39        17\n",
      "weighted avg       0.42      0.65      0.51        17\n",
      "\n",
      "Participant: cresh24\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.21052631578947367\n",
      "F1 micro on validation set: 0.21052631578947367\n",
      "F1 macro on validation set: 0.16176470588235295\n",
      "Confusion Matrix: \n",
      "[[ 2  0  0]\n",
      " [10  2  0]\n",
      " [ 3  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.13      1.00      0.24         2\n",
      "        10.0       0.50      0.17      0.25        12\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.21        19\n",
      "   macro avg       0.21      0.39      0.16        19\n",
      "weighted avg       0.33      0.21      0.18        19\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.21052631578947367\n",
      "F1 micro on validation set: 0.21052631578947367\n",
      "F1 macro on validation set: 0.13968253968253966\n",
      "Confusion Matrix: \n",
      "[[ 1 13  0]\n",
      " [ 0  3  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       1.00      0.07      0.13        14\n",
      "        10.0       0.17      1.00      0.29         3\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.21        19\n",
      "   macro avg       0.39      0.36      0.14        19\n",
      "weighted avg       0.76      0.21      0.14        19\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5789473684210527\n",
      "F1 micro on validation set: 0.5789473684210527\n",
      "F1 macro on validation set: 0.5476190476190476\n",
      "Confusion Matrix: \n",
      "[[3 6]\n",
      " [2 8]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.60      0.33      0.43         9\n",
      "        11.0       0.57      0.80      0.67        10\n",
      "\n",
      "    accuracy                           0.58        19\n",
      "   macro avg       0.59      0.57      0.55        19\n",
      "weighted avg       0.58      0.58      0.55        19\n",
      "\n",
      "Participant: cresh28\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.3757575757575758\n",
      "Confusion Matrix: \n",
      "[[0 0 0]\n",
      " [3 2 0]\n",
      " [0 3 4]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "        10.0       0.40      0.40      0.40         5\n",
      "        11.0       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.47      0.32      0.38        12\n",
      "weighted avg       0.75      0.50      0.59        12\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.42857142857142855\n",
      "Confusion Matrix: \n",
      "[[9 3]\n",
      " [0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.75      0.86        12\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.50      0.38      0.43        12\n",
      "weighted avg       1.00      0.75      0.86        12\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.6571428571428571\n",
      "Confusion Matrix: \n",
      "[[5 4]\n",
      " [0 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.56      0.71         9\n",
      "        11.0       0.43      1.00      0.60         3\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.71      0.78      0.66        12\n",
      "weighted avg       0.86      0.67      0.69        12\n",
      "\n",
      "Participant: cresh25\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'temperature_mbient'\n",
      " 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_cooler' 'user_grouped_warmer' 'room_grouped_cooler'\n",
      " 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.4666666666666667\n",
      "F1 micro on validation set: 0.4666666666666667\n",
      "F1 macro on validation set: 0.34432234432234426\n",
      "Confusion Matrix: \n",
      "[[4 4 1]\n",
      " [1 3 2]\n",
      " [0 0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.80      0.44      0.57         9\n",
      "        10.0       0.43      0.50      0.46         6\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.47        15\n",
      "   macro avg       0.41      0.31      0.34        15\n",
      "weighted avg       0.65      0.47      0.53        15\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_dimmer'\n",
      " 'user_grouped_brighter' 'room_grouped_dimmer' 'room_grouped_brighter'\n",
      " 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3333333333333333\n",
      "F1 micro on validation set: 0.3333333333333333\n",
      "F1 macro on validation set: 0.16666666666666666\n",
      "Confusion Matrix: \n",
      "[[0 9 0]\n",
      " [0 5 0]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         9\n",
      "        10.0       0.33      1.00      0.50         5\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.11      0.33      0.17        15\n",
      "weighted avg       0.11      0.33      0.17        15\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'temperature_mbient' 'hour_sin'\n",
      " 'hour_cos' 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_quieter'\n",
      " 'user_grouped_louder' 'room_grouped_quieter' 'room_grouped_louder'\n",
      " 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8666666666666667\n",
      "F1 micro on validation set: 0.8666666666666667\n",
      "F1 macro on validation set: 0.4642857142857143\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.87      1.00      0.93        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.43      0.50      0.46        15\n",
      "weighted avg       0.75      0.87      0.80        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for participant in participant_list:\n",
    "    print(\"Participant: {}\\n\".format(participant))\n",
    "    df_train = pd.read_csv(\"../\" + df_file + \"_train_\" + participant + \".csv\")\n",
    "    df_val = pd.read_csv(\"../\" + df_file + \"_val_\" + participant + \".csv\")\n",
    "    # drop userid\n",
    "    df_train.drop('user_id', axis=1, inplace=True)\n",
    "    df_val.drop('user_id', axis=1, inplace=True)\n",
    "    # drop room\n",
    "    df_train.drop('room', axis=1, inplace=True)\n",
    "    df_val.drop('room', axis=1, inplace=True)\n",
    "\n",
    "    ###########################################################################\n",
    "    # thermal comfort prediction\n",
    "    df_train_thermal = df_train.copy()\n",
    "    df_val_thermal = df_val.copy()\n",
    "    \n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_dimmer', 'user_grouped_brighter', 'user_grouped_quieter', 'user_grouped_louder',\n",
    "                         'room_grouped_dimmer', 'room_grouped_brighter', 'room_grouped_quieter', 'room_grouped_louder']\n",
    "\n",
    "    df_train_thermal.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_thermal.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_thermal.columns.values)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_4_thermal, macro_rf_4_thermal, _ = model_validate(df_train_thermal, df_val_thermal, clf)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # light comfort prediction\n",
    "    df_train_light = df_train.copy()\n",
    "    df_val_light = df_val.copy()\n",
    "\n",
    "    # move light response to the end\n",
    "    df_aux = df_train_light.pop('light_cozie')\n",
    "    df_train_light['light_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val_light.pop('light_cozie')\n",
    "    df_val_light['light_cozie'] = df_aux\n",
    "\n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_cooler', 'user_grouped_warmer', 'user_grouped_quieter', 'user_grouped_louder',\n",
    "                         'room_grouped_cooler', 'room_grouped_warmer', 'room_grouped_quieter', 'room_grouped_louder']\n",
    "\n",
    "    df_train_light.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_light.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_light.columns.values)\n",
    "\n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_4_light, macro_rf_4_light, _ = model_validate(df_train_light, df_val_light, clf)\n",
    "        \n",
    "    ###########################################################################\n",
    "    # aural comfort prediction\n",
    "    df_train_aural = df_train.copy()\n",
    "    df_val_aural = df_val.copy()\n",
    "\n",
    "    # move aural response to the end\n",
    "    df_aux = df_train_aural.pop('noise_cozie')\n",
    "    df_train_aural['noise_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val_aural.pop('noise_cozie')\n",
    "    df_val_aural['noise_cozie'] = df_aux\n",
    "\n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_cooler', 'user_grouped_warmer', 'user_grouped_dimmer', 'user_grouped_brighter',\n",
    "                         'room_grouped_cooler', 'room_grouped_warmer', 'room_grouped_dimmer', 'room_grouped_brighter']\n",
    "\n",
    "    df_train_aural.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_aural.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_aural.columns.values)\n",
    "\n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_4_aural, macro_rf_4_aural, _ = model_validate(df_train_aural, df_val_aural, clf)\n",
    "\n",
    "    # append all participant's responses for this feature set\n",
    "    list_micro_fs4_thermal[participant] = micro_rf_4_thermal\n",
    "    list_macro_fs4_thermal[participant] = macro_rf_4_thermal\n",
    "\n",
    "    list_micro_fs4_light[participant] = micro_rf_4_light\n",
    "    list_macro_fs4_light[participant] = macro_rf_4_light\n",
    "\n",
    "    list_micro_fs4_aural[participant] = micro_rf_4_aural\n",
    "    list_macro_fs4_aural[participant] = macro_rf_4_aural\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# FS5: Time + Heart Rate + room + preference history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from: data-processed-preferences/2019-11-15_fs5\n"
     ]
    }
   ],
   "source": [
    "df_file = folder_path + file_date + \"_\" +  dataframes_names[4]\n",
    "print(\"Loading files from: {}\".format(df_file))\n",
    "\n",
    "list_micro_fs5_thermal = {}\n",
    "list_macro_fs5_thermal = {}\n",
    "\n",
    "list_micro_fs5_light = {}\n",
    "list_macro_fs5_light = {}\n",
    "\n",
    "list_micro_fs5_aural = {}\n",
    "list_macro_fs5_aural = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: cresh07\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5263157894736842\n",
      "F1 micro on validation set: 0.5263157894736842\n",
      "F1 macro on validation set: 0.2298850574712644\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 10  7]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.83      0.59      0.69        17\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53        19\n",
      "   macro avg       0.28      0.20      0.23        19\n",
      "weighted avg       0.75      0.53      0.62        19\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[19]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        19\n",
      "   macro avg       1.00      1.00      1.00        19\n",
      "weighted avg       1.00      1.00      1.00        19\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9473684210526315\n",
      "F1 micro on validation set: 0.9473684210526315\n",
      "F1 macro on validation set: 0.4864864864864865\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        18\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.47      0.50      0.49        19\n",
      "weighted avg       0.90      0.95      0.92        19\n",
      "\n",
      "Participant: cresh10\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.4444444444444444\n",
      "F1 micro on validation set: 0.4444444444444444\n",
      "F1 macro on validation set: 0.3050108932461874\n",
      "Confusion Matrix: \n",
      "[[0 0 1]\n",
      " [0 4 9]\n",
      " [0 0 4]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       1.00      0.31      0.47        13\n",
      "        11.0       0.29      1.00      0.44         4\n",
      "\n",
      "    accuracy                           0.44        18\n",
      "   macro avg       0.43      0.44      0.31        18\n",
      "weighted avg       0.79      0.44      0.44        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.30303030303030304\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.83      1.00      0.91        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.28      0.33      0.30        18\n",
      "weighted avg       0.69      0.83      0.76        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.45454545454545453\n",
      "Confusion Matrix: \n",
      "[[15  2]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      0.88      0.91        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.47      0.44      0.45        18\n",
      "weighted avg       0.89      0.83      0.86        18\n",
      "\n",
      "Participant: cresh08\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.42857142857142855\n",
      "Confusion Matrix: \n",
      "[[12  4]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.75      0.86        16\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.50      0.38      0.43        16\n",
      "weighted avg       1.00      0.75      0.86        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8125\n",
      "F1 micro on validation set: 0.8125\n",
      "F1 macro on validation set: 0.4482758620689655\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.81      1.00      0.90        13\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.41      0.50      0.45        16\n",
      "weighted avg       0.66      0.81      0.73        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9375\n",
      "F1 micro on validation set: 0.9375\n",
      "F1 macro on validation set: 0.4838709677419355\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        15\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.47      0.50      0.48        16\n",
      "weighted avg       0.88      0.94      0.91        16\n",
      "\n",
      "Participant: cresh12\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.5252525252525252\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0  5  0]\n",
      " [ 0  2 10]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.50      1.00      0.67         5\n",
      "        11.0       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.50      0.61      0.53        20\n",
      "weighted avg       0.72      0.75      0.71        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9\n",
      "F1 micro on validation set: 0.9\n",
      "F1 macro on validation set: 0.4736842105263158\n",
      "Confusion Matrix: \n",
      "[[ 0  2]\n",
      " [ 0 18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      1.00      0.95        18\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.45      0.50      0.47        20\n",
      "weighted avg       0.81      0.90      0.85        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8\n",
      "F1 micro on validation set: 0.8000000000000002\n",
      "F1 macro on validation set: 0.4444444444444445\n",
      "Confusion Matrix: \n",
      "[[16  0]\n",
      " [ 4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.80      1.00      0.89        16\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.40      0.50      0.44        20\n",
      "weighted avg       0.64      0.80      0.71        20\n",
      "\n",
      "Participant: cresh09\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.35\n",
      "F1 micro on validation set: 0.35\n",
      "F1 macro on validation set: 0.22826086956521738\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0  5 11]\n",
      " [ 0  1  2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.71      0.31      0.43        16\n",
      "        11.0       0.15      0.67      0.25         3\n",
      "\n",
      "    accuracy                           0.35        20\n",
      "   macro avg       0.29      0.33      0.23        20\n",
      "weighted avg       0.59      0.35      0.39        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.95\n",
      "F1 micro on validation set: 0.9500000000000001\n",
      "F1 macro on validation set: 0.48717948717948717\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        19\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.47      0.50      0.49        20\n",
      "weighted avg       0.90      0.95      0.93        20\n",
      "\n",
      "Participant: cresh06\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5510204081632653\n",
      "F1 micro on validation set: 0.5510204081632653\n",
      "F1 macro on validation set: 0.39054373522458624\n",
      "Confusion Matrix: \n",
      "[[12  8  0]\n",
      " [ 8 15  0]\n",
      " [ 5  1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.48      0.60      0.53        20\n",
      "        10.0       0.62      0.65      0.64        23\n",
      "        11.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.55        49\n",
      "   macro avg       0.37      0.42      0.39        49\n",
      "weighted avg       0.49      0.55      0.52        49\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8367346938775511\n",
      "F1 micro on validation set: 0.8367346938775511\n",
      "F1 macro on validation set: 0.45555555555555555\n",
      "Confusion Matrix: \n",
      "[[ 0  8]\n",
      " [ 0 41]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         8\n",
      "        10.0       0.84      1.00      0.91        41\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.42      0.50      0.46        49\n",
      "weighted avg       0.70      0.84      0.76        49\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8571428571428571\n",
      "F1 micro on validation set: 0.8571428571428571\n",
      "F1 macro on validation set: 0.4615384615384615\n",
      "Confusion Matrix: \n",
      "[[42  0]\n",
      " [ 7  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.86      1.00      0.92        42\n",
      "        11.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.86        49\n",
      "   macro avg       0.43      0.50      0.46        49\n",
      "weighted avg       0.73      0.86      0.79        49\n",
      "\n",
      "Participant: cresh02\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.625\n",
      "F1 micro on validation set: 0.625\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[ 0  2  1]\n",
      " [ 0  1  2]\n",
      " [ 0  4 14]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.14      0.33      0.20         3\n",
      "        11.0       0.82      0.78      0.80        18\n",
      "\n",
      "    accuracy                           0.62        24\n",
      "   macro avg       0.32      0.37      0.33        24\n",
      "weighted avg       0.64      0.62      0.62        24\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.4166666666666667\n",
      "F1 micro on validation set: 0.4166666666666667\n",
      "F1 macro on validation set: 0.3636141636141636\n",
      "Confusion Matrix: \n",
      "[[1 0 1]\n",
      " [3 7 2]\n",
      " [1 7 2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.20      0.50      0.29         2\n",
      "        10.0       0.50      0.58      0.54        12\n",
      "        11.0       0.40      0.20      0.27        10\n",
      "\n",
      "    accuracy                           0.42        24\n",
      "   macro avg       0.37      0.43      0.36        24\n",
      "weighted avg       0.43      0.42      0.40        24\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5416666666666666\n",
      "F1 micro on validation set: 0.5416666666666666\n",
      "F1 macro on validation set: 0.4197802197802198\n",
      "Confusion Matrix: \n",
      "[[12  6]\n",
      " [ 5  1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.71      0.67      0.69        18\n",
      "        11.0       0.14      0.17      0.15         6\n",
      "\n",
      "    accuracy                           0.54        24\n",
      "   macro avg       0.42      0.42      0.42        24\n",
      "weighted avg       0.57      0.54      0.55        24\n",
      "\n",
      "Participant: cresh13\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.494949494949495\n",
      "Confusion Matrix: \n",
      "[[4 1]\n",
      " [9 6]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.31      0.80      0.44         5\n",
      "        11.0       0.86      0.40      0.55        15\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.58      0.60      0.49        20\n",
      "weighted avg       0.72      0.50      0.52        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.25\n",
      "F1 micro on validation set: 0.25\n",
      "F1 macro on validation set: 0.24812030075187969\n",
      "Confusion Matrix: \n",
      "[[ 2  4]\n",
      " [11  3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.15      0.33      0.21         6\n",
      "        10.0       0.43      0.21      0.29        14\n",
      "\n",
      "    accuracy                           0.25        20\n",
      "   macro avg       0.29      0.27      0.25        20\n",
      "weighted avg       0.35      0.25      0.26        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.65\n",
      "F1 micro on validation set: 0.65\n",
      "F1 macro on validation set: 0.6491228070175439\n",
      "Confusion Matrix: \n",
      "[[6 6]\n",
      " [1 7]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.86      0.50      0.63        12\n",
      "        11.0       0.54      0.88      0.67         8\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.70      0.69      0.65        20\n",
      "weighted avg       0.73      0.65      0.65        20\n",
      "\n",
      "Participant: cresh15\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9333333333333333\n",
      "F1 micro on validation set: 0.9333333333333333\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0 14]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.00      0.00      0.00         0\n",
      "        11.0       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.33      0.33      0.33        15\n",
      "weighted avg       0.93      0.93      0.93        15\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.26666666666666666\n",
      "F1 micro on validation set: 0.26666666666666666\n",
      "F1 macro on validation set: 0.25339366515837103\n",
      "Confusion Matrix: \n",
      "[[ 3 11]\n",
      " [ 0  1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       1.00      0.21      0.35        14\n",
      "        10.0       0.08      1.00      0.15         1\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.54      0.61      0.25        15\n",
      "weighted avg       0.94      0.27      0.34        15\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5333333333333333\n",
      "F1 micro on validation set: 0.5333333333333333\n",
      "F1 macro on validation set: 0.4444444444444444\n",
      "Confusion Matrix: \n",
      "[[1 0]\n",
      " [7 7]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.12      1.00      0.22         1\n",
      "        11.0       1.00      0.50      0.67        14\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.56      0.75      0.44        15\n",
      "weighted avg       0.94      0.53      0.64        15\n",
      "\n",
      "Participant: cresh03\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9444444444444444\n",
      "F1 micro on validation set: 0.9444444444444444\n",
      "F1 macro on validation set: 0.4857142857142857\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.94      0.97        18\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.50      0.47      0.49        18\n",
      "weighted avg       1.00      0.94      0.97        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6111111111111112\n",
      "F1 micro on validation set: 0.6111111111111112\n",
      "F1 macro on validation set: 0.5696881091617932\n",
      "Confusion Matrix: \n",
      "[[3 0 0]\n",
      " [2 1 3]\n",
      " [0 2 7]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.60      1.00      0.75         3\n",
      "        10.0       0.33      0.17      0.22         6\n",
      "        11.0       0.70      0.78      0.74         9\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.54      0.65      0.57        18\n",
      "weighted avg       0.56      0.61      0.57        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9444444444444444\n",
      "F1 micro on validation set: 0.9444444444444444\n",
      "F1 macro on validation set: 0.4857142857142857\n",
      "Confusion Matrix: \n",
      "[[17  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.47      0.50      0.49        18\n",
      "weighted avg       0.89      0.94      0.92        18\n",
      "\n",
      "Participant: cresh14\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.37037037037037035\n",
      "F1 micro on validation set: 0.37037037037037035\n",
      "F1 macro on validation set: 0.3097744360902256\n",
      "Confusion Matrix: \n",
      "[[ 1  6]\n",
      " [11  9]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.08      0.14      0.11         7\n",
      "        10.0       0.60      0.45      0.51        20\n",
      "\n",
      "    accuracy                           0.37        27\n",
      "   macro avg       0.34      0.30      0.31        27\n",
      "weighted avg       0.47      0.37      0.41        27\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[27]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           1.00        27\n",
      "   macro avg       1.00      1.00      1.00        27\n",
      "weighted avg       1.00      1.00      1.00        27\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9629629629629629\n",
      "F1 micro on validation set: 0.9629629629629629\n",
      "F1 macro on validation set: 0.49056603773584906\n",
      "Confusion Matrix: \n",
      "[[26  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      1.00      0.98        26\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        27\n",
      "   macro avg       0.48      0.50      0.49        27\n",
      "weighted avg       0.93      0.96      0.94        27\n",
      "\n",
      "Participant: cresh11\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[8 0]\n",
      " [8 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.50      1.00      0.67         8\n",
      "        11.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.3125\n",
      "F1 micro on validation set: 0.3125\n",
      "F1 macro on validation set: 0.30980392156862746\n",
      "Confusion Matrix: \n",
      "[[2 2]\n",
      " [9 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.18      0.50      0.27         4\n",
      "        11.0       0.60      0.25      0.35        12\n",
      "\n",
      "    accuracy                           0.31        16\n",
      "   macro avg       0.39      0.38      0.31        16\n",
      "weighted avg       0.50      0.31      0.33        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh05\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.27777777777777773\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 15  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.71      1.00      0.83        15\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.24      0.33      0.28        21\n",
      "weighted avg       0.51      0.71      0.60        21\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8571428571428571\n",
      "F1 micro on validation set: 0.8571428571428571\n",
      "F1 macro on validation set: 0.3076923076923077\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 18  1]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      0.95      0.92        19\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86        21\n",
      "   macro avg       0.30      0.32      0.31        21\n",
      "weighted avg       0.81      0.86      0.84        21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "Participant: cresh01\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6190476190476191\n",
      "F1 micro on validation set: 0.6190476190476191\n",
      "F1 macro on validation set: 0.25490196078431376\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 13  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.62      1.00      0.76        13\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.62        21\n",
      "   macro avg       0.21      0.33      0.25        21\n",
      "weighted avg       0.38      0.62      0.47        21\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.47252747252747246\n",
      "Confusion Matrix: \n",
      "[[11  0  0]\n",
      " [ 4  4  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.73      1.00      0.85        11\n",
      "        10.0       0.67      0.50      0.57         8\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.47      0.50      0.47        21\n",
      "weighted avg       0.64      0.71      0.66        21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9047619047619048\n",
      "F1 micro on validation set: 0.9047619047619048\n",
      "F1 macro on validation set: 0.47500000000000003\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.90      1.00      0.95        19\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.45      0.50      0.48        21\n",
      "weighted avg       0.82      0.90      0.86        21\n",
      "\n",
      "Participant: cresh04\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh22\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.4761904761904761\n",
      "Confusion Matrix: \n",
      "[[4 1 0]\n",
      " [3 3 0]\n",
      " [0 4 1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.57      0.80      0.67         5\n",
      "        10.0       0.38      0.50      0.43         6\n",
      "        11.0       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.65      0.50      0.48        16\n",
      "weighted avg       0.63      0.50      0.47        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8125\n",
      "F1 micro on validation set: 0.8125\n",
      "F1 macro on validation set: 0.4482758620689655\n",
      "Confusion Matrix: \n",
      "[[13  1]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.87      0.93      0.90        14\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.43      0.46      0.45        16\n",
      "weighted avg       0.76      0.81      0.78        16\n",
      "\n",
      "Participant: cresh16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.2777777777777778\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 20  1]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.74      0.95      0.83        21\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.25      0.32      0.28        28\n",
      "weighted avg       0.56      0.71      0.62        28\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Participant: cresh19\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.625\n",
      "F1 micro on validation set: 0.625\n",
      "F1 macro on validation set: 0.25641025641025644\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.62      1.00      0.77        10\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.21      0.33      0.26        16\n",
      "weighted avg       0.39      0.62      0.48        16\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.47619047619047616\n",
      "F1 micro on validation set: 0.47619047619047616\n",
      "F1 macro on validation set: 0.42962962962962964\n",
      "Confusion Matrix: \n",
      "[[ 8  0]\n",
      " [11  2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.42      1.00      0.59         8\n",
      "        11.0       1.00      0.15      0.27        13\n",
      "\n",
      "    accuracy                           0.48        21\n",
      "   macro avg       0.71      0.58      0.43        21\n",
      "weighted avg       0.78      0.48      0.39        21\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9523809523809523\n",
      "F1 micro on validation set: 0.9523809523809523\n",
      "F1 macro on validation set: 0.4878048780487805\n",
      "Confusion Matrix: \n",
      "[[20  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.98        20\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.48      0.50      0.49        21\n",
      "weighted avg       0.91      0.95      0.93        21\n",
      "\n",
      "Participant: cresh26\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8235294117647058\n",
      "F1 micro on validation set: 0.8235294117647058\n",
      "F1 macro on validation set: 0.3010752688172043\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0 14  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.82      1.00      0.90        14\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.27      0.33      0.30        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8235294117647058\n",
      "F1 micro on validation set: 0.8235294117647058\n",
      "F1 macro on validation set: 0.45161290322580644\n",
      "Confusion Matrix: \n",
      "[[14  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.82      1.00      0.90        14\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.41      0.50      0.45        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8823529411764706\n",
      "F1 micro on validation set: 0.8823529411764706\n",
      "F1 macro on validation set: 0.46875\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      1.00      0.94        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.44      0.50      0.47        17\n",
      "weighted avg       0.78      0.88      0.83        17\n",
      "\n",
      "Participant: cresh29\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Participant: cresh27\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9166666666666666\n",
      "F1 micro on validation set: 0.9166666666666666\n",
      "F1 macro on validation set: 0.4782608695652174\n",
      "Confusion Matrix: \n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.92      1.00      0.96        11\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5833333333333334\n",
      "F1 micro on validation set: 0.5833333333333334\n",
      "F1 macro on validation set: 0.4957983193277311\n",
      "Confusion Matrix: \n",
      "[[6 4]\n",
      " [1 1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.86      0.60      0.71        10\n",
      "        11.0       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.53      0.55      0.50        12\n",
      "weighted avg       0.75      0.58      0.64        12\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9166666666666666\n",
      "F1 micro on validation set: 0.9166666666666666\n",
      "F1 macro on validation set: 0.4782608695652174\n",
      "Confusion Matrix: \n",
      "[[11  1]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.92      0.96        12\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "Participant: cresh23\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7777777777777778\n",
      "F1 micro on validation set: 0.7777777777777778\n",
      "F1 macro on validation set: 0.29166666666666663\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 14  1]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.82      0.93      0.87        15\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.27      0.31      0.29        18\n",
      "weighted avg       0.69      0.78      0.73        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.2666666666666667\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 1 12  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.71      0.92      0.80        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.24      0.31      0.27        18\n",
      "weighted avg       0.51      0.67      0.58        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.3888888888888889\n",
      "F1 micro on validation set: 0.3888888888888889\n",
      "F1 macro on validation set: 0.28\n",
      "Confusion Matrix: \n",
      "[[7 2]\n",
      " [9 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.44      0.78      0.56         9\n",
      "        11.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.39        18\n",
      "   macro avg       0.22      0.39      0.28        18\n",
      "weighted avg       0.22      0.39      0.28        18\n",
      "\n",
      "Participant: cresh20\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6111111111111112\n",
      "F1 micro on validation set: 0.6111111111111112\n",
      "F1 macro on validation set: 0.3793103448275862\n",
      "Confusion Matrix: \n",
      "[[ 0  1]\n",
      " [ 6 11]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.46      0.32      0.38        18\n",
      "weighted avg       0.87      0.61      0.72        18\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh18\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.72\n",
      "F1 micro on validation set: 0.72\n",
      "F1 macro on validation set: 0.27906976744186046\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 18  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.72      1.00      0.84        18\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.72        25\n",
      "   macro avg       0.24      0.33      0.28        25\n",
      "weighted avg       0.52      0.72      0.60        25\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[25]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.88\n",
      "F1 micro on validation set: 0.88\n",
      "F1 macro on validation set: 0.4680851063829787\n",
      "Confusion Matrix: \n",
      "[[22  2]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      0.92      0.94        24\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.88        25\n",
      "   macro avg       0.48      0.46      0.47        25\n",
      "weighted avg       0.92      0.88      0.90        25\n",
      "\n",
      "Participant: cresh30\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6923076923076923\n",
      "F1 micro on validation set: 0.6923076923076923\n",
      "F1 macro on validation set: 0.28571428571428575\n",
      "Confusion Matrix: \n",
      "[[0 1 1]\n",
      " [0 9 1]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.82      0.90      0.86        10\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.27      0.30      0.29        13\n",
      "weighted avg       0.63      0.69      0.66        13\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8461538461538461\n",
      "F1 micro on validation set: 0.8461538461538461\n",
      "F1 macro on validation set: 0.4583333333333333\n",
      "Confusion Matrix: \n",
      "[[11  1]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.92      0.92      0.92        12\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.46      0.46      0.46        13\n",
      "weighted avg       0.85      0.85      0.85        13\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.7692307692307693\n",
      "F1 micro on validation set: 0.7692307692307693\n",
      "F1 macro on validation set: 0.43478260869565216\n",
      "Confusion Matrix: \n",
      "[[10  1]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.83      0.91      0.87        11\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.42      0.45      0.43        13\n",
      "weighted avg       0.71      0.77      0.74        13\n",
      "\n",
      "Participant: cresh17\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6470588235294118\n",
      "F1 micro on validation set: 0.6470588235294118\n",
      "F1 macro on validation set: 0.38509316770186336\n",
      "Confusion Matrix: \n",
      "[[ 1  2  0]\n",
      " [ 1  0  1]\n",
      " [ 2  0 10]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.25      0.33      0.29         3\n",
      "        10.0       0.00      0.00      0.00         2\n",
      "        11.0       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.39      0.39      0.39        17\n",
      "weighted avg       0.69      0.65      0.66        17\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.23529411764705882\n",
      "F1 micro on validation set: 0.23529411764705882\n",
      "F1 macro on validation set: 0.1762820512820513\n",
      "Confusion Matrix: \n",
      "[[3 0 0]\n",
      " [8 1 0]\n",
      " [2 3 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.23      1.00      0.38         3\n",
      "        10.0       0.25      0.11      0.15         9\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.24        17\n",
      "   macro avg       0.16      0.37      0.18        17\n",
      "weighted avg       0.17      0.24      0.15        17\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6470588235294118\n",
      "F1 micro on validation set: 0.6470588235294118\n",
      "F1 macro on validation set: 0.3928571428571429\n",
      "Confusion Matrix: \n",
      "[[ 0  6]\n",
      " [ 0 11]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.00      0.00      0.00         6\n",
      "        11.0       0.65      1.00      0.79        11\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.32      0.50      0.39        17\n",
      "weighted avg       0.42      0.65      0.51        17\n",
      "\n",
      "Participant: cresh24\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.2631578947368421\n",
      "F1 micro on validation set: 0.2631578947368421\n",
      "F1 macro on validation set: 0.2074074074074074\n",
      "Confusion Matrix: \n",
      "[[2 0 0]\n",
      " [9 3 0]\n",
      " [5 0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.12      1.00      0.22         2\n",
      "        10.0       1.00      0.25      0.40        12\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.26        19\n",
      "   macro avg       0.38      0.42      0.21        19\n",
      "weighted avg       0.64      0.26      0.28        19\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.2631578947368421\n",
      "F1 micro on validation set: 0.2631578947368421\n",
      "F1 macro on validation set: 0.18369453044375642\n",
      "Confusion Matrix: \n",
      "[[ 2 12  0]\n",
      " [ 0  3  0]\n",
      " [ 1  1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.67      0.14      0.24        14\n",
      "        10.0       0.19      1.00      0.32         3\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.26        19\n",
      "   macro avg       0.28      0.38      0.18        19\n",
      "weighted avg       0.52      0.26      0.22        19\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5263157894736842\n",
      "F1 micro on validation set: 0.5263157894736842\n",
      "F1 macro on validation set: 0.3448275862068966\n",
      "Confusion Matrix: \n",
      "[[ 0  9]\n",
      " [ 0 10]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.00      0.00      0.00         9\n",
      "        11.0       0.53      1.00      0.69        10\n",
      "\n",
      "    accuracy                           0.53        19\n",
      "   macro avg       0.26      0.50      0.34        19\n",
      "weighted avg       0.28      0.53      0.36        19\n",
      "\n",
      "Participant: cresh28\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.4166666666666667\n",
      "F1 micro on validation set: 0.4166666666666667\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[0 0 0]\n",
      " [3 2 0]\n",
      " [1 3 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "        10.0       0.40      0.40      0.40         5\n",
      "        11.0       1.00      0.43      0.60         7\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.47      0.28      0.33        12\n",
      "weighted avg       0.75      0.42      0.52        12\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.4\n",
      "Confusion Matrix: \n",
      "[[8 4]\n",
      " [0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.67      0.80        12\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.50      0.33      0.40        12\n",
      "weighted avg       1.00      0.67      0.80        12\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.6571428571428571\n",
      "Confusion Matrix: \n",
      "[[5 4]\n",
      " [0 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.56      0.71         9\n",
      "        11.0       0.43      1.00      0.60         3\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.71      0.78      0.66        12\n",
      "weighted avg       0.86      0.67      0.69        12\n",
      "\n",
      "Participant: cresh25\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos'\n",
      " 'day_of_week_sin' 'day_of_week_cos' 'user_grouped_cooler'\n",
      " 'user_grouped_warmer' 'room_grouped_cooler' 'room_grouped_warmer'\n",
      " 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.4666666666666667\n",
      "F1 micro on validation set: 0.4666666666666667\n",
      "F1 macro on validation set: 0.34432234432234426\n",
      "Confusion Matrix: \n",
      "[[4 4 1]\n",
      " [1 3 2]\n",
      " [0 0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.80      0.44      0.57         9\n",
      "        10.0       0.43      0.50      0.46         6\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.47        15\n",
      "   macro avg       0.41      0.31      0.34        15\n",
      "weighted avg       0.65      0.47      0.53        15\n",
      "\n",
      "['heartRate_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_dimmer' 'user_grouped_brighter'\n",
      " 'room_grouped_dimmer' 'room_grouped_brighter' 'thermal_cozie'\n",
      " 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3333333333333333\n",
      "F1 micro on validation set: 0.3333333333333333\n",
      "F1 macro on validation set: 0.16666666666666666\n",
      "Confusion Matrix: \n",
      "[[0 9 0]\n",
      " [0 5 0]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         9\n",
      "        10.0       0.33      1.00      0.50         5\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.11      0.33      0.17        15\n",
      "weighted avg       0.11      0.33      0.17        15\n",
      "\n",
      "['heartRate_cozie' 'light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_quieter' 'user_grouped_louder'\n",
      " 'room_grouped_quieter' 'room_grouped_louder' 'thermal_cozie'\n",
      " 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8666666666666667\n",
      "F1 micro on validation set: 0.8666666666666667\n",
      "F1 macro on validation set: 0.4642857142857143\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.87      1.00      0.93        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.43      0.50      0.46        15\n",
      "weighted avg       0.75      0.87      0.80        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for participant in participant_list:\n",
    "    print(\"Participant: {}\\n\".format(participant))\n",
    "    df_train = pd.read_csv(\"../\" + df_file + \"_train_\" + participant + \".csv\")\n",
    "    df_val = pd.read_csv(\"../\" + df_file + \"_val_\" + participant + \".csv\")\n",
    "    # drop userid\n",
    "    df_train.drop('user_id', axis=1, inplace=True)\n",
    "    df_val.drop('user_id', axis=1, inplace=True)\n",
    "    # drop room\n",
    "    df_train.drop('room', axis=1, inplace=True)\n",
    "    df_val.drop('room', axis=1, inplace=True)\n",
    "\n",
    "    ###########################################################################\n",
    "    # thermal comfort prediction\n",
    "    df_train_thermal = df_train.copy()\n",
    "    df_val_thermal = df_val.copy()\n",
    "    \n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_dimmer', 'user_grouped_brighter', 'user_grouped_quieter', 'user_grouped_louder',\n",
    "                         'room_grouped_dimmer', 'room_grouped_brighter', 'room_grouped_quieter', 'room_grouped_louder']\n",
    "\n",
    "    df_train_thermal.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_thermal.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_thermal.columns.values)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_5_thermal, macro_rf_5_thermal, _ = model_validate(df_train_thermal, df_val_thermal, clf)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # light comfort prediction\n",
    "    df_train_light = df_train.copy()\n",
    "    df_val_light = df_val.copy()\n",
    "\n",
    "    # move light response to the end\n",
    "    df_aux = df_train_light.pop('light_cozie')\n",
    "    df_train_light['light_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val_light.pop('light_cozie')\n",
    "    df_val_light['light_cozie'] = df_aux\n",
    "\n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_cooler', 'user_grouped_warmer', 'user_grouped_quieter', 'user_grouped_louder',\n",
    "                         'room_grouped_cooler', 'room_grouped_warmer', 'room_grouped_quieter', 'room_grouped_louder']\n",
    "\n",
    "    df_train_light.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_light.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_light.columns.values)\n",
    "\n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_5_light, macro_rf_5_light, _ = model_validate(df_train_light, df_val_light, clf)\n",
    "        \n",
    "    ###########################################################################\n",
    "    # aural comfort prediction\n",
    "    df_train_aural = df_train.copy()\n",
    "    df_val_aural = df_val.copy()\n",
    "\n",
    "    # move aural response to the end\n",
    "    df_aux = df_train_aural.pop('noise_cozie')\n",
    "    df_train_aural['noise_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val_aural.pop('noise_cozie')\n",
    "    df_val_aural['noise_cozie'] = df_aux\n",
    "\n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_cooler', 'user_grouped_warmer', 'user_grouped_dimmer', 'user_grouped_brighter',\n",
    "                         'room_grouped_cooler', 'room_grouped_warmer', 'room_grouped_dimmer', 'room_grouped_brighter']\n",
    "\n",
    "    df_train_aural.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_aural.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_aural.columns.values)\n",
    "\n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_5_aural, macro_rf_5_aural, _ = model_validate(df_train_aural, df_val_aural, clf)\n",
    "\n",
    "    # append all participant's responses for this feature set\n",
    "    list_micro_fs5_thermal[participant] = micro_rf_5_thermal\n",
    "    list_macro_fs5_thermal[participant] = macro_rf_5_thermal\n",
    "\n",
    "    list_micro_fs5_light[participant] = micro_rf_5_light\n",
    "    list_macro_fs5_light[participant] = macro_rf_5_light\n",
    "\n",
    "    list_micro_fs5_aural[participant] = micro_rf_5_aural\n",
    "    list_macro_fs5_aural[participant] = macro_rf_5_aural\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# FS6: Time + room + preference history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from: data-processed-preferences/2019-11-15_fs6\n"
     ]
    }
   ],
   "source": [
    "df_file = folder_path + file_date + \"_\" +  dataframes_names[5]\n",
    "print(\"Loading files from: {}\".format(df_file))\n",
    "\n",
    "list_micro_fs6_thermal = {}\n",
    "list_macro_fs6_thermal = {}\n",
    "\n",
    "list_micro_fs6_light = {}\n",
    "list_macro_fs6_light = {}\n",
    "\n",
    "list_micro_fs6_aural = {}\n",
    "list_macro_fs6_aural = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: cresh07\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5263157894736842\n",
      "F1 micro on validation set: 0.5263157894736842\n",
      "F1 macro on validation set: 0.2298850574712644\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 10  7]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.83      0.59      0.69        17\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53        19\n",
      "   macro avg       0.28      0.20      0.23        19\n",
      "weighted avg       0.75      0.53      0.62        19\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[19]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        19\n",
      "   macro avg       1.00      1.00      1.00        19\n",
      "weighted avg       1.00      1.00      1.00        19\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9473684210526315\n",
      "F1 micro on validation set: 0.9473684210526315\n",
      "F1 macro on validation set: 0.4864864864864865\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        18\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.47      0.50      0.49        19\n",
      "weighted avg       0.90      0.95      0.92        19\n",
      "\n",
      "Participant: cresh10\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3333333333333333\n",
      "F1 micro on validation set: 0.3333333333333333\n",
      "F1 macro on validation set: 0.22222222222222224\n",
      "Confusion Matrix: \n",
      "[[ 0  0  1]\n",
      " [ 0  2 11]\n",
      " [ 0  0  4]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       1.00      0.15      0.27        13\n",
      "        11.0       0.25      1.00      0.40         4\n",
      "\n",
      "    accuracy                           0.33        18\n",
      "   macro avg       0.42      0.38      0.22        18\n",
      "weighted avg       0.78      0.33      0.28        18\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.30303030303030304\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.83      1.00      0.91        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.28      0.33      0.30        18\n",
      "weighted avg       0.69      0.83      0.76        18\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8333333333333334\n",
      "F1 micro on validation set: 0.8333333333333334\n",
      "F1 macro on validation set: 0.45454545454545453\n",
      "Confusion Matrix: \n",
      "[[15  2]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      0.88      0.91        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.47      0.44      0.45        18\n",
      "weighted avg       0.89      0.83      0.86        18\n",
      "\n",
      "Participant: cresh08\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.75\n",
      "F1 micro on validation set: 0.75\n",
      "F1 macro on validation set: 0.42857142857142855\n",
      "Confusion Matrix: \n",
      "[[12  4]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.75      0.86        16\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.50      0.38      0.43        16\n",
      "weighted avg       1.00      0.75      0.86        16\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8125\n",
      "F1 micro on validation set: 0.8125\n",
      "F1 macro on validation set: 0.4482758620689655\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.81      1.00      0.90        13\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.41      0.50      0.45        16\n",
      "weighted avg       0.66      0.81      0.73        16\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9375\n",
      "F1 micro on validation set: 0.9375\n",
      "F1 macro on validation set: 0.4838709677419355\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        15\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.47      0.50      0.48        16\n",
      "weighted avg       0.88      0.94      0.91        16\n",
      "\n",
      "Participant: cresh12\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8\n",
      "F1 micro on validation set: 0.8000000000000002\n",
      "F1 macro on validation set: 0.556935817805383\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0  5  0]\n",
      " [ 0  1 11]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.56      1.00      0.71         5\n",
      "        11.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.52      0.64      0.56        20\n",
      "weighted avg       0.74      0.80      0.75        20\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9\n",
      "F1 micro on validation set: 0.9\n",
      "F1 macro on validation set: 0.4736842105263158\n",
      "Confusion Matrix: \n",
      "[[ 0  2]\n",
      " [ 0 18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      1.00      0.95        18\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.45      0.50      0.47        20\n",
      "weighted avg       0.81      0.90      0.85        20\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8\n",
      "F1 micro on validation set: 0.8000000000000002\n",
      "F1 macro on validation set: 0.4444444444444445\n",
      "Confusion Matrix: \n",
      "[[16  0]\n",
      " [ 4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.80      1.00      0.89        16\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.40      0.50      0.44        20\n",
      "weighted avg       0.64      0.80      0.71        20\n",
      "\n",
      "Participant: cresh09\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.15\n",
      "F1 micro on validation set: 0.15\n",
      "F1 macro on validation set: 0.10052910052910054\n",
      "Confusion Matrix: \n",
      "[[ 0  0  1]\n",
      " [ 0  1 15]\n",
      " [ 0  1  2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.50      0.06      0.11        16\n",
      "        11.0       0.11      0.67      0.19         3\n",
      "\n",
      "    accuracy                           0.15        20\n",
      "   macro avg       0.20      0.24      0.10        20\n",
      "weighted avg       0.42      0.15      0.12        20\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.95\n",
      "F1 micro on validation set: 0.9500000000000001\n",
      "F1 macro on validation set: 0.48717948717948717\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.97        19\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.47      0.50      0.49        20\n",
      "weighted avg       0.90      0.95      0.93        20\n",
      "\n",
      "Participant: cresh06\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.32653061224489793\n",
      "F1 micro on validation set: 0.32653061224489793\n",
      "F1 macro on validation set: 0.23582766439909297\n",
      "Confusion Matrix: \n",
      "[[ 8 11  1]\n",
      " [15  8  0]\n",
      " [ 6  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.28      0.40      0.33        20\n",
      "        10.0       0.42      0.35      0.38        23\n",
      "        11.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.33        49\n",
      "   macro avg       0.23      0.25      0.24        49\n",
      "weighted avg       0.31      0.33      0.31        49\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8367346938775511\n",
      "F1 micro on validation set: 0.8367346938775511\n",
      "F1 macro on validation set: 0.45555555555555555\n",
      "Confusion Matrix: \n",
      "[[ 0  8]\n",
      " [ 0 41]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         8\n",
      "        10.0       0.84      1.00      0.91        41\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.42      0.50      0.46        49\n",
      "weighted avg       0.70      0.84      0.76        49\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8571428571428571\n",
      "F1 micro on validation set: 0.8571428571428571\n",
      "F1 macro on validation set: 0.4615384615384615\n",
      "Confusion Matrix: \n",
      "[[42  0]\n",
      " [ 7  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.86      1.00      0.92        42\n",
      "        11.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.86        49\n",
      "   macro avg       0.43      0.50      0.46        49\n",
      "weighted avg       0.73      0.86      0.79        49\n",
      "\n",
      "Participant: cresh02\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.625\n",
      "F1 micro on validation set: 0.625\n",
      "F1 macro on validation set: 0.34074074074074073\n",
      "Confusion Matrix: \n",
      "[[ 0  2  1]\n",
      " [ 0  1  2]\n",
      " [ 1  3 14]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.17      0.33      0.22         3\n",
      "        11.0       0.82      0.78      0.80        18\n",
      "\n",
      "    accuracy                           0.62        24\n",
      "   macro avg       0.33      0.37      0.34        24\n",
      "weighted avg       0.64      0.62      0.63        24\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.3333333333333333\n",
      "F1 micro on validation set: 0.3333333333333333\n",
      "F1 macro on validation set: 0.3111111111111111\n",
      "Confusion Matrix: \n",
      "[[1 0 1]\n",
      " [4 4 4]\n",
      " [3 4 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.12      0.50      0.20         2\n",
      "        10.0       0.50      0.33      0.40        12\n",
      "        11.0       0.38      0.30      0.33        10\n",
      "\n",
      "    accuracy                           0.33        24\n",
      "   macro avg       0.33      0.38      0.31        24\n",
      "weighted avg       0.42      0.33      0.36        24\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5833333333333334\n",
      "F1 micro on validation set: 0.5833333333333334\n",
      "F1 macro on validation set: 0.4444444444444444\n",
      "Confusion Matrix: \n",
      "[[13  5]\n",
      " [ 5  1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.72      0.72      0.72        18\n",
      "        11.0       0.17      0.17      0.17         6\n",
      "\n",
      "    accuracy                           0.58        24\n",
      "   macro avg       0.44      0.44      0.44        24\n",
      "weighted avg       0.58      0.58      0.58        24\n",
      "\n",
      "Participant: cresh13\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.55\n",
      "F1 micro on validation set: 0.55\n",
      "F1 macro on validation set: 0.5396419437340153\n",
      "Confusion Matrix: \n",
      "[[4 1]\n",
      " [8 7]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.33      0.80      0.47         5\n",
      "        11.0       0.88      0.47      0.61        15\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.60      0.63      0.54        20\n",
      "weighted avg       0.74      0.55      0.57        20\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.2\n",
      "F1 micro on validation set: 0.20000000000000004\n",
      "F1 macro on validation set: 0.2\n",
      "Confusion Matrix: \n",
      "[[ 2  4]\n",
      " [12  2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.14      0.33      0.20         6\n",
      "        10.0       0.33      0.14      0.20        14\n",
      "\n",
      "    accuracy                           0.20        20\n",
      "   macro avg       0.24      0.24      0.20        20\n",
      "weighted avg       0.28      0.20      0.20        20\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6\n",
      "F1 micro on validation set: 0.6\n",
      "F1 macro on validation set: 0.595959595959596\n",
      "Confusion Matrix: \n",
      "[[5 7]\n",
      " [1 7]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.83      0.42      0.56        12\n",
      "        11.0       0.50      0.88      0.64         8\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.67      0.65      0.60        20\n",
      "weighted avg       0.70      0.60      0.59        20\n",
      "\n",
      "Participant: cresh15\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9333333333333333\n",
      "F1 micro on validation set: 0.9333333333333333\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0 14]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.00      0.00      0.00         0\n",
      "        11.0       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.33      0.33      0.33        15\n",
      "weighted avg       0.93      0.93      0.93        15\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5333333333333333\n",
      "F1 micro on validation set: 0.5333333333333333\n",
      "F1 macro on validation set: 0.4444444444444444\n",
      "Confusion Matrix: \n",
      "[[7 7]\n",
      " [0 1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       1.00      0.50      0.67        14\n",
      "        10.0       0.12      1.00      0.22         1\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.56      0.75      0.44        15\n",
      "weighted avg       0.94      0.53      0.64        15\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5333333333333333\n",
      "F1 micro on validation set: 0.5333333333333333\n",
      "F1 macro on validation set: 0.4444444444444444\n",
      "Confusion Matrix: \n",
      "[[1 0]\n",
      " [7 7]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.12      1.00      0.22         1\n",
      "        11.0       1.00      0.50      0.67        14\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.56      0.75      0.44        15\n",
      "weighted avg       0.94      0.53      0.64        15\n",
      "\n",
      "Participant: cresh03\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9444444444444444\n",
      "F1 micro on validation set: 0.9444444444444444\n",
      "F1 macro on validation set: 0.4857142857142857\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.94      0.97        18\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.50      0.47      0.49        18\n",
      "weighted avg       1.00      0.94      0.97        18\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.4605263157894736\n",
      "Confusion Matrix: \n",
      "[[3 0 0]\n",
      " [2 0 4]\n",
      " [0 3 6]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.60      1.00      0.75         3\n",
      "        10.0       0.00      0.00      0.00         6\n",
      "        11.0       0.60      0.67      0.63         9\n",
      "\n",
      "    accuracy                           0.50        18\n",
      "   macro avg       0.40      0.56      0.46        18\n",
      "weighted avg       0.40      0.50      0.44        18\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9444444444444444\n",
      "F1 micro on validation set: 0.9444444444444444\n",
      "F1 macro on validation set: 0.4857142857142857\n",
      "Confusion Matrix: \n",
      "[[17  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.94      1.00      0.97        17\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.47      0.50      0.49        18\n",
      "weighted avg       0.89      0.94      0.92        18\n",
      "\n",
      "Participant: cresh14\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.4074074074074074\n",
      "F1 micro on validation set: 0.4074074074074074\n",
      "F1 macro on validation set: 0.33333333333333337\n",
      "Confusion Matrix: \n",
      "[[ 1  6]\n",
      " [10 10]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.09      0.14      0.11         7\n",
      "        10.0       0.62      0.50      0.56        20\n",
      "\n",
      "    accuracy                           0.41        27\n",
      "   macro avg       0.36      0.32      0.33        27\n",
      "weighted avg       0.49      0.41      0.44        27\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[27]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           1.00        27\n",
      "   macro avg       1.00      1.00      1.00        27\n",
      "weighted avg       1.00      1.00      1.00        27\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9629629629629629\n",
      "F1 micro on validation set: 0.9629629629629629\n",
      "F1 macro on validation set: 0.49056603773584906\n",
      "Confusion Matrix: \n",
      "[[26  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      1.00      0.98        26\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        27\n",
      "   macro avg       0.48      0.50      0.49        27\n",
      "weighted avg       0.93      0.96      0.94        27\n",
      "\n",
      "Participant: cresh11\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[8 0]\n",
      " [8 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.50      1.00      0.67         8\n",
      "        11.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.25\n",
      "F1 micro on validation set: 0.25\n",
      "F1 macro on validation set: 0.1722222222222222\n",
      "Confusion Matrix: \n",
      "[[0 0 0]\n",
      " [0 2 2]\n",
      " [1 9 2]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "        10.0       0.18      0.50      0.27         4\n",
      "        11.0       0.50      0.17      0.25        12\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.23      0.22      0.17        16\n",
      "weighted avg       0.42      0.25      0.25        16\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh05\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.27777777777777773\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 15  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.71      1.00      0.83        15\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.24      0.33      0.28        21\n",
      "weighted avg       0.51      0.71      0.60        21\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8571428571428571\n",
      "F1 micro on validation set: 0.8571428571428571\n",
      "F1 macro on validation set: 0.3076923076923077\n",
      "Confusion Matrix: \n",
      "[[ 0  2  0]\n",
      " [ 0 18  1]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.90      0.95      0.92        19\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86        21\n",
      "   macro avg       0.30      0.32      0.31        21\n",
      "weighted avg       0.81      0.86      0.84        21\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "Participant: cresh01\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5714285714285714\n",
      "F1 micro on validation set: 0.5714285714285714\n",
      "F1 macro on validation set: 0.24242424242424246\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 1 12  0]\n",
      " [ 0  4  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.60      0.92      0.73        13\n",
      "        11.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.57        21\n",
      "   macro avg       0.20      0.31      0.24        21\n",
      "weighted avg       0.37      0.57      0.45        21\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.47252747252747246\n",
      "Confusion Matrix: \n",
      "[[11  0  0]\n",
      " [ 4  4  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.73      1.00      0.85        11\n",
      "        10.0       0.67      0.50      0.57         8\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.47      0.50      0.47        21\n",
      "weighted avg       0.64      0.71      0.66        21\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9047619047619048\n",
      "F1 micro on validation set: 0.9047619047619048\n",
      "F1 macro on validation set: 0.47500000000000003\n",
      "Confusion Matrix: \n",
      "[[19  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.90      1.00      0.95        19\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.45      0.50      0.48        21\n",
      "weighted avg       0.82      0.90      0.86        21\n",
      "\n",
      "Participant: cresh04\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh22\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5\n",
      "F1 micro on validation set: 0.5\n",
      "F1 macro on validation set: 0.4202020202020202\n",
      "Confusion Matrix: \n",
      "[[4 1 0]\n",
      " [1 4 1]\n",
      " [1 4 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.67      0.80      0.73         5\n",
      "        10.0       0.44      0.67      0.53         6\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.37      0.49      0.42        16\n",
      "weighted avg       0.38      0.50      0.43        16\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.875\n",
      "F1 micro on validation set: 0.875\n",
      "F1 macro on validation set: 0.4666666666666667\n",
      "Confusion Matrix: \n",
      "[[14  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      1.00      0.93        14\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.44      0.50      0.47        16\n",
      "weighted avg       0.77      0.88      0.82        16\n",
      "\n",
      "Participant: cresh16\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7142857142857143\n",
      "F1 micro on validation set: 0.7142857142857143\n",
      "F1 macro on validation set: 0.3864734299516908\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 19  2]\n",
      " [ 0  2  1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.76      0.90      0.83        21\n",
      "        11.0       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.36      0.41      0.39        28\n",
      "weighted avg       0.61      0.71      0.66        28\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[28]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Participant: cresh19\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.625\n",
      "F1 micro on validation set: 0.625\n",
      "F1 macro on validation set: 0.25641025641025644\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.62      1.00      0.77        10\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.21      0.33      0.26        16\n",
      "weighted avg       0.39      0.62      0.48        16\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[16]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Participant: cresh21\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.42857142857142855\n",
      "F1 micro on validation set: 0.42857142857142855\n",
      "F1 macro on validation set: 0.3571428571428572\n",
      "Confusion Matrix: \n",
      "[[ 8  0]\n",
      " [12  1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.40      1.00      0.57         8\n",
      "        11.0       1.00      0.08      0.14        13\n",
      "\n",
      "    accuracy                           0.43        21\n",
      "   macro avg       0.70      0.54      0.36        21\n",
      "weighted avg       0.77      0.43      0.31        21\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[21]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9523809523809523\n",
      "F1 micro on validation set: 0.9523809523809523\n",
      "F1 macro on validation set: 0.4878048780487805\n",
      "Confusion Matrix: \n",
      "[[20  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.95      1.00      0.98        20\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.48      0.50      0.49        21\n",
      "weighted avg       0.91      0.95      0.93        21\n",
      "\n",
      "Participant: cresh26\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8235294117647058\n",
      "F1 micro on validation set: 0.8235294117647058\n",
      "F1 macro on validation set: 0.3010752688172043\n",
      "Confusion Matrix: \n",
      "[[ 0  1  0]\n",
      " [ 0 14  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.82      1.00      0.90        14\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.27      0.33      0.30        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8235294117647058\n",
      "F1 micro on validation set: 0.8235294117647058\n",
      "F1 macro on validation set: 0.45161290322580644\n",
      "Confusion Matrix: \n",
      "[[14  0]\n",
      " [ 3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.82      1.00      0.90        14\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.41      0.50      0.45        17\n",
      "weighted avg       0.68      0.82      0.74        17\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8823529411764706\n",
      "F1 micro on validation set: 0.8823529411764706\n",
      "F1 macro on validation set: 0.46875\n",
      "Confusion Matrix: \n",
      "[[15  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.88      1.00      0.94        15\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.44      0.50      0.47        17\n",
      "weighted avg       0.78      0.88      0.83        17\n",
      "\n",
      "Participant: cresh29\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[20]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Participant: cresh27\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9166666666666666\n",
      "F1 micro on validation set: 0.9166666666666666\n",
      "F1 macro on validation set: 0.4782608695652174\n",
      "Confusion Matrix: \n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.92      1.00      0.96        11\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5833333333333334\n",
      "F1 micro on validation set: 0.5833333333333334\n",
      "F1 macro on validation set: 0.3452380952380952\n",
      "Confusion Matrix: \n",
      "[[0 0 0]\n",
      " [0 6 4]\n",
      " [1 0 1]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "        10.0       1.00      0.60      0.75        10\n",
      "        11.0       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.40      0.37      0.35        12\n",
      "weighted avg       0.87      0.58      0.67        12\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.9166666666666666\n",
      "F1 micro on validation set: 0.9166666666666666\n",
      "F1 macro on validation set: 0.4782608695652174\n",
      "Confusion Matrix: \n",
      "[[11  1]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.92      0.96        12\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "Participant: cresh23\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7777777777777778\n",
      "F1 micro on validation set: 0.7777777777777778\n",
      "F1 macro on validation set: 0.29166666666666663\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 0 14  1]\n",
      " [ 0  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.82      0.93      0.87        15\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.27      0.31      0.29        18\n",
      "weighted avg       0.69      0.78      0.73        18\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.2666666666666667\n",
      "Confusion Matrix: \n",
      "[[ 0  3  0]\n",
      " [ 1 12  0]\n",
      " [ 0  2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         3\n",
      "        10.0       0.71      0.92      0.80        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.24      0.31      0.27        18\n",
      "weighted avg       0.51      0.67      0.58        18\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.3888888888888889\n",
      "F1 micro on validation set: 0.3888888888888889\n",
      "F1 macro on validation set: 0.28\n",
      "Confusion Matrix: \n",
      "[[7 2]\n",
      " [9 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.44      0.78      0.56         9\n",
      "        11.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.39        18\n",
      "   macro avg       0.22      0.39      0.28        18\n",
      "weighted avg       0.22      0.39      0.28        18\n",
      "\n",
      "Participant: cresh20\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6111111111111112\n",
      "F1 micro on validation set: 0.6111111111111112\n",
      "F1 macro on validation set: 0.3793103448275862\n",
      "Confusion Matrix: \n",
      "[[ 0  1]\n",
      " [ 6 11]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.46      0.32      0.38        18\n",
      "weighted avg       0.87      0.61      0.72        18\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.7222222222222222\n",
      "F1 micro on validation set: 0.7222222222222222\n",
      "F1 macro on validation set: 0.4193548387096774\n",
      "Confusion Matrix: \n",
      "[[13  5]\n",
      " [ 0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.72      0.84        18\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.50      0.36      0.42        18\n",
      "weighted avg       1.00      0.72      0.84        18\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[18]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Participant: cresh18\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.72\n",
      "F1 micro on validation set: 0.72\n",
      "F1 macro on validation set: 0.27906976744186046\n",
      "Confusion Matrix: \n",
      "[[ 0  4  0]\n",
      " [ 0 18  0]\n",
      " [ 0  3  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.72      1.00      0.84        18\n",
      "        11.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.72        25\n",
      "   macro avg       0.24      0.33      0.28        25\n",
      "weighted avg       0.52      0.72      0.60        25\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 1.0\n",
      "F1 micro on validation set: 1.0\n",
      "F1 macro on validation set: 1.0\n",
      "Confusion Matrix: \n",
      "[[25]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.88\n",
      "F1 micro on validation set: 0.88\n",
      "F1 macro on validation set: 0.4680851063829787\n",
      "Confusion Matrix: \n",
      "[[22  2]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.96      0.92      0.94        24\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.88        25\n",
      "   macro avg       0.48      0.46      0.47        25\n",
      "weighted avg       0.92      0.88      0.90        25\n",
      "\n",
      "Participant: cresh30\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6923076923076923\n",
      "F1 micro on validation set: 0.6923076923076923\n",
      "F1 macro on validation set: 0.28571428571428575\n",
      "Confusion Matrix: \n",
      "[[0 1 1]\n",
      " [0 9 1]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "        10.0       0.82      0.90      0.86        10\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.27      0.30      0.29        13\n",
      "weighted avg       0.63      0.69      0.66        13\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8461538461538461\n",
      "F1 micro on validation set: 0.8461538461538461\n",
      "F1 macro on validation set: 0.4583333333333333\n",
      "Confusion Matrix: \n",
      "[[11  1]\n",
      " [ 1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.92      0.92      0.92        12\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.46      0.46      0.46        13\n",
      "weighted avg       0.85      0.85      0.85        13\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.8461538461538461\n",
      "F1 micro on validation set: 0.8461538461538461\n",
      "F1 macro on validation set: 0.4583333333333333\n",
      "Confusion Matrix: \n",
      "[[11  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.85      1.00      0.92        11\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.42      0.50      0.46        13\n",
      "weighted avg       0.72      0.85      0.78        13\n",
      "\n",
      "Participant: cresh17\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6470588235294118\n",
      "F1 micro on validation set: 0.6470588235294118\n",
      "F1 macro on validation set: 0.38509316770186336\n",
      "Confusion Matrix: \n",
      "[[ 1  2  0]\n",
      " [ 1  0  1]\n",
      " [ 2  0 10]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.25      0.33      0.29         3\n",
      "        10.0       0.00      0.00      0.00         2\n",
      "        11.0       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.39      0.39      0.39        17\n",
      "weighted avg       0.69      0.65      0.66        17\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.23529411764705882\n",
      "F1 micro on validation set: 0.23529411764705882\n",
      "F1 macro on validation set: 0.17825311942959002\n",
      "Confusion Matrix: \n",
      "[[3 0 0]\n",
      " [7 1 1]\n",
      " [4 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.21      1.00      0.35         3\n",
      "        10.0       0.50      0.11      0.18         9\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.24        17\n",
      "   macro avg       0.24      0.37      0.18        17\n",
      "weighted avg       0.30      0.24      0.16        17\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.6470588235294118\n",
      "F1 micro on validation set: 0.6470588235294118\n",
      "F1 macro on validation set: 0.3928571428571429\n",
      "Confusion Matrix: \n",
      "[[ 0  6]\n",
      " [ 0 11]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.00      0.00      0.00         6\n",
      "        11.0       0.65      1.00      0.79        11\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.32      0.50      0.39        17\n",
      "weighted avg       0.42      0.65      0.51        17\n",
      "\n",
      "Participant: cresh24\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.21052631578947367\n",
      "F1 micro on validation set: 0.21052631578947367\n",
      "F1 macro on validation set: 0.16541353383458646\n",
      "Confusion Matrix: \n",
      "[[ 2  0  0]\n",
      " [10  2  0]\n",
      " [ 5  0  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.12      1.00      0.21         2\n",
      "        10.0       1.00      0.17      0.29        12\n",
      "        11.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.21        19\n",
      "   macro avg       0.37      0.39      0.17        19\n",
      "weighted avg       0.64      0.21      0.20        19\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.2631578947368421\n",
      "F1 micro on validation set: 0.2631578947368421\n",
      "F1 macro on validation set: 0.18369453044375642\n",
      "Confusion Matrix: \n",
      "[[ 2 12  0]\n",
      " [ 0  3  0]\n",
      " [ 1  1  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.67      0.14      0.24        14\n",
      "        10.0       0.19      1.00      0.32         3\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.26        19\n",
      "   macro avg       0.28      0.38      0.18        19\n",
      "weighted avg       0.52      0.26      0.22        19\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.5789473684210527\n",
      "F1 micro on validation set: 0.5789473684210527\n",
      "F1 macro on validation set: 0.45714285714285713\n",
      "Confusion Matrix: \n",
      "[[ 1  8]\n",
      " [ 0 10]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.11      0.20         9\n",
      "        11.0       0.56      1.00      0.71        10\n",
      "\n",
      "    accuracy                           0.58        19\n",
      "   macro avg       0.78      0.56      0.46        19\n",
      "weighted avg       0.77      0.58      0.47        19\n",
      "\n",
      "Participant: cresh28\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.4166666666666667\n",
      "F1 micro on validation set: 0.4166666666666667\n",
      "F1 macro on validation set: 0.34814814814814815\n",
      "Confusion Matrix: \n",
      "[[0 0 0]\n",
      " [3 2 0]\n",
      " [2 2 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "        10.0       0.50      0.40      0.44         5\n",
      "        11.0       1.00      0.43      0.60         7\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.50      0.28      0.35        12\n",
      "weighted avg       0.79      0.42      0.54        12\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.5833333333333334\n",
      "F1 micro on validation set: 0.5833333333333334\n",
      "F1 macro on validation set: 0.3684210526315789\n",
      "Confusion Matrix: \n",
      "[[7 5]\n",
      " [0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.58      0.74        12\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.50      0.29      0.37        12\n",
      "weighted avg       1.00      0.58      0.74        12\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.6666666666666666\n",
      "F1 micro on validation set: 0.6666666666666666\n",
      "F1 macro on validation set: 0.6571428571428571\n",
      "Confusion Matrix: \n",
      "[[5 4]\n",
      " [0 3]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       1.00      0.56      0.71         9\n",
      "        11.0       0.43      1.00      0.60         3\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.71      0.78      0.66        12\n",
      "weighted avg       0.86      0.67      0.69        12\n",
      "\n",
      "Participant: cresh25\n",
      "\n",
      "['light_cozie' 'noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin'\n",
      " 'day_of_week_cos' 'user_grouped_cooler' 'user_grouped_warmer'\n",
      " 'room_grouped_cooler' 'room_grouped_warmer' 'thermal_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.4666666666666667\n",
      "F1 micro on validation set: 0.4666666666666667\n",
      "F1 macro on validation set: 0.34432234432234426\n",
      "Confusion Matrix: \n",
      "[[4 4 1]\n",
      " [1 3 2]\n",
      " [0 0 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.80      0.44      0.57         9\n",
      "        10.0       0.43      0.50      0.46         6\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.47        15\n",
      "   macro avg       0.41      0.31      0.34        15\n",
      "weighted avg       0.65      0.47      0.53        15\n",
      "\n",
      "['noise_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_dimmer' 'user_grouped_brighter' 'room_grouped_dimmer'\n",
      " 'room_grouped_brighter' 'thermal_cozie' 'light_cozie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (f1 micro) on validation set: 0.3333333333333333\n",
      "F1 micro on validation set: 0.3333333333333333\n",
      "F1 macro on validation set: 0.16666666666666666\n",
      "Confusion Matrix: \n",
      "[[0 9 0]\n",
      " [0 5 0]\n",
      " [0 1 0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         9.0       0.00      0.00      0.00         9\n",
      "        10.0       0.33      1.00      0.50         5\n",
      "        11.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.11      0.33      0.17        15\n",
      "weighted avg       0.11      0.33      0.17        15\n",
      "\n",
      "['light_cozie' 'hour_sin' 'hour_cos' 'day_of_week_sin' 'day_of_week_cos'\n",
      " 'user_grouped_quieter' 'user_grouped_louder' 'room_grouped_quieter'\n",
      " 'room_grouped_louder' 'thermal_cozie' 'noise_cozie']\n",
      "Accuracy (f1 micro) on validation set: 0.8666666666666667\n",
      "F1 micro on validation set: 0.8666666666666667\n",
      "F1 macro on validation set: 0.4642857142857143\n",
      "Confusion Matrix: \n",
      "[[13  0]\n",
      " [ 2  0]]\n",
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        10.0       0.87      1.00      0.93        13\n",
      "        11.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.43      0.50      0.46        15\n",
      "weighted avg       0.75      0.87      0.80        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/matias/miniconda3/envs/cresh-data-crunch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for participant in participant_list:\n",
    "    print(\"Participant: {}\\n\".format(participant))\n",
    "    df_train = pd.read_csv(\"../\" + df_file + \"_train_\" + participant + \".csv\")\n",
    "    df_val = pd.read_csv(\"../\" + df_file + \"_val_\" + participant + \".csv\")\n",
    "    # drop userid\n",
    "    df_train.drop('user_id', axis=1, inplace=True)\n",
    "    df_val.drop('user_id', axis=1, inplace=True)\n",
    "    # drop room\n",
    "    df_train.drop('room', axis=1, inplace=True)\n",
    "    df_val.drop('room', axis=1, inplace=True)\n",
    "\n",
    "    ###########################################################################\n",
    "    # thermal comfort prediction\n",
    "    df_train_thermal = df_train.copy()\n",
    "    df_val_thermal = df_val.copy()\n",
    "    \n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_dimmer', 'user_grouped_brighter', 'user_grouped_quieter', 'user_grouped_louder',\n",
    "                         'room_grouped_dimmer', 'room_grouped_brighter', 'room_grouped_quieter', 'room_grouped_louder']\n",
    "\n",
    "    df_train_thermal.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_thermal.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_thermal.columns.values)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_6_thermal, macro_rf_6_thermal, _ = model_validate(df_train_thermal, df_val_thermal, clf)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # light comfort prediction\n",
    "    df_train_light = df_train.copy()\n",
    "    df_val_light = df_val.copy()\n",
    "\n",
    "    # move light response to the end\n",
    "    df_aux = df_train_light.pop('light_cozie')\n",
    "    df_train_light['light_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val_light.pop('light_cozie')\n",
    "    df_val_light['light_cozie'] = df_aux\n",
    "\n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_cooler', 'user_grouped_warmer', 'user_grouped_quieter', 'user_grouped_louder',\n",
    "                         'room_grouped_cooler', 'room_grouped_warmer', 'room_grouped_quieter', 'room_grouped_louder']\n",
    "\n",
    "    df_train_light.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_light.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_light.columns.values)\n",
    "\n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_6_light, macro_rf_6_light, _ = model_validate(df_train_light, df_val_light, clf)\n",
    "        \n",
    "    ###########################################################################\n",
    "    # aural comfort prediction\n",
    "    df_train_aural = df_train.copy()\n",
    "    df_val_aural = df_val.copy()\n",
    "\n",
    "    # move aural response to the end\n",
    "    df_aux = df_train_aural.pop('noise_cozie')\n",
    "    df_train_aural['noise_cozie'] = df_aux\n",
    "\n",
    "    df_aux = df_val_aural.pop('noise_cozie')\n",
    "    df_val_aural['noise_cozie'] = df_aux\n",
    "\n",
    "    # drop other preferences\n",
    "    other_preferences = ['user_grouped_cooler', 'user_grouped_warmer', 'user_grouped_dimmer', 'user_grouped_brighter',\n",
    "                         'room_grouped_cooler', 'room_grouped_warmer', 'room_grouped_dimmer', 'room_grouped_brighter']\n",
    "\n",
    "    df_train_aural.drop(other_preferences, axis=1, inplace=True)\n",
    "    df_val_aural.drop(other_preferences, axis=1, inplace=True)\n",
    "\n",
    "    print(df_train_aural.columns.values)\n",
    "\n",
    "    # train and validate model\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = seed)\n",
    "    micro_rf_6_aural, macro_rf_6_aural, _ = model_validate(df_train_aural, df_val_aural, clf)\n",
    "\n",
    "    # append all participant's responses for this feature set\n",
    "    list_micro_fs6_thermal[participant] = micro_rf_6_thermal\n",
    "    list_macro_fs6_thermal[participant] = macro_rf_6_thermal\n",
    "\n",
    "    list_micro_fs6_light[participant] = micro_rf_6_light\n",
    "    list_macro_fs6_light[participant] = macro_rf_6_light\n",
    "\n",
    "    list_micro_fs6_aural[participant] = micro_rf_6_aural\n",
    "    list_macro_fs6_aural[participant] = macro_rf_6_aural\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results_personal_micro = {\n",
    "    \"fs1_thermal\" : list_micro_fs1_thermal,\n",
    "    \"fs1_light\" : list_micro_fs1_light,\n",
    "    \"fs1_aural\" : list_micro_fs1_aural,\n",
    "\n",
    "    \"fs2_thermal\" : list_micro_fs2_thermal,\n",
    "    \"fs2_light\" : list_micro_fs2_light,\n",
    "    \"fs2_aural\" : list_micro_fs2_aural,\n",
    "    \n",
    "    \"fs3_thermal\" : list_micro_fs3_thermal,\n",
    "    \"fs3_light\" : list_micro_fs3_light,\n",
    "    \"fs3_aural\" : list_micro_fs3_aural,\n",
    "\n",
    "    \"fs4_thermal\" : list_micro_fs4_thermal,\n",
    "    \"fs4_light\" : list_micro_fs4_light,\n",
    "    \"fs4_aural\" : list_micro_fs4_aural,\n",
    "\n",
    "    \"fs5_thermal\" : list_micro_fs5_thermal,\n",
    "    \"fs5_light\" : list_micro_fs5_light,\n",
    "    \"fs5_aural\" : list_micro_fs5_aural,\n",
    "    \n",
    "    \"fs6_thermal\" : list_micro_fs6_thermal,\n",
    "    \"fs6_light\" : list_micro_fs6_light,\n",
    "    \"fs6_aural\" : list_micro_fs6_aural,\n",
    "}\n",
    "\n",
    "dict_results_personal_macro = {\n",
    "    \"fs1_thermal\" : list_macro_fs1_thermal,\n",
    "    \"fs1_light\" : list_macro_fs1_light,\n",
    "    \"fs1_aural\" : list_macro_fs1_aural,\n",
    "\n",
    "    \"fs2_thermal\" : list_macro_fs2_thermal,\n",
    "    \"fs2_light\" : list_macro_fs2_light,\n",
    "    \"fs2_aural\" : list_macro_fs2_aural,\n",
    "    \n",
    "    \"fs3_thermal\" : list_macro_fs3_thermal,\n",
    "    \"fs3_light\" : list_macro_fs3_light,\n",
    "    \"fs3_aural\" : list_macro_fs3_aural,\n",
    "\n",
    "    \"fs4_thermal\" : list_macro_fs4_thermal,\n",
    "    \"fs4_light\" : list_macro_fs4_light,\n",
    "    \"fs4_aural\" : list_macro_fs4_aural,\n",
    "\n",
    "    \"fs5_thermal\" : list_macro_fs5_thermal,\n",
    "    \"fs5_light\" : list_macro_fs5_light,\n",
    "    \"fs5_aural\" : list_macro_fs5_aural,\n",
    "    \n",
    "    \"fs6_thermal\" : list_macro_fs6_thermal,\n",
    "    \"fs6_light\" : list_macro_fs6_light,\n",
    "    \"fs6_aural\" : list_macro_fs6_aural,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionaries with results\n",
    "pickle.dump(dict_results_personal_micro, open(\"../\" + folder_path + file_date + \"_personal_micro\" + \".pickle\", \"wb\" ))\n",
    "pickle.dump(dict_results_personal_macro, open(\"../\" + folder_path + file_date + \"_personal_macro\" + \".pickle\", \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cresh-data-crunch",
   "language": "python",
   "name": "cresh-data-crunch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
